# [Comunicaci√≥n as√≠ncrona entre microservicios usando SpringBoot 3 con Kafka, Redis y Docker](https://www.youtube.com/watch?v=kIc3ORaZM-I)

---

## Arquitectura del proyecto

La soluci√≥n se compone de dos microservicios que se comunican de manera as√≠ncrona mediante `Kafka`, y que utilizan un
`Redis` compartido como `sistema de cach√©`.

### 1. News Service

- Expone una `API REST` para que los clientes consulten noticias.
- Flujo:
    - Revisa primero si la noticia solicitada se encuentra en `Redis`.
    - Si existe en cach√© ‚Üí responde inmediatamente al cliente.
    - Si no existe en cach√© ‚Üí produce un mensaje en `Kafka (news-topic)` indicando que debe obtenerse esa noticia.

### 2. Worker Service

- Est√° suscrito al topic `news-topic`.
- Flujo:
    - Escucha el mensaje enviado por el `news-service`.
    - Verifica en `Redis` si ya existe la noticia.
    - Si no est√° ‚Üí consulta la API externa `Mediastack`.
    - Guarda la respuesta obtenida en `Redis`, quedando disponible para futuras consultas.

#### 3. Redis (√∫nico y compartido)

- Ambos servicios se conectan a la misma instancia de `Redis`, que act√∫a como cach√© centralizada.
- Permite que:
    - El `news-service` pueda responder r√°pidamente si la noticia ya fue procesada.
    - El `worker-service` guarde los resultados para que luego el `news-service` los entregue a los clientes.

![01.png](assets/01.png)

### Nota sobre la integraci√≥n con Redis

En este proyecto, ambos microservicios se conectan a la misma instancia de `Redis`, pero cada uno utiliza un cliente
diferente para prop√≥sitos de pr√°ctica y aprendizaje:

- `News Service`. Se conecta a `Redis` utilizando la dependencia `spring-boot-starter-data-redis-reactive`, la cual
  internamente emplea el cliente `Lettuce`. Esta elecci√≥n est√° alineada con el contenido del curso principal, ya que se
  centra en trabajar con `Spring Data Redis` en su variante reactiva.


- `Worker Service`. En este caso `no se usa` `Spring Data Redis Reactive`. En su lugar, se integra `Redis` a trav√©s de
  `redisson-spring-boot-starter`, aprovechando el cliente `Redisson`. Esta decisi√≥n se tom√≥ como parte de la pr√°ctica
  de un curso previo de `Redis`, lo que permite explorar un enfoque alternativo de conexi√≥n y manejo de datos en
  `Redis`.

De esta forma, aunque ambos microservicios comparten la misma instancia de `Redis` como sistema de cach√© centralizado,
cada uno lo hace con un cliente distinto, lo que enriquece el aprendizaje y la comparaci√≥n entre enfoques.

## Creando proyecto: [news-service](https://start.spring.io/#!type=maven-project&language=java&platformVersion=3.5.5&packaging=jar&jvmVersion=21&groupId=dev.magadiflo&artifactId=news-service&name=news-service&description=Demo%20project%20for%20Spring%20Boot&packageName=dev.magadiflo.news.app&dependencies=webflux,lombok,data-redis-reactive,kafka,validation)

Creamos el proyecto `news-service` desde spring initializr con las siguientes dependencias.

````xml
<!--Spring Boot 3.5.5-->
<!--Java 21-->
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-redis-reactive</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-validation</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-webflux</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>

    <dependency>
        <groupId>org.projectlombok</groupId>
        <artifactId>lombok</artifactId>
        <optional>true</optional>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-test</artifactId>
        <scope>test</scope>
    </dependency>
    <dependency>
        <groupId>io.projectreactor</groupId>
        <artifactId>reactor-test</artifactId>
        <scope>test</scope>
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka-test</artifactId>
        <scope>test</scope>
    </dependency>
</dependencies>
````

> `Nota`: usamos `spring-boot-starter-data-redis-reactive` porque `WebFlux` est√° basado en el paradigma reactivo. Esto
> garantiza operaciones no bloqueantes tambi√©n en el acceso a `Redis`.

## Configuraci√≥n de News Service

Definimos las configuraciones b√°sicas para que nuestro `news-service` pueda conectarse a `Kafka` y a `Redis`.

````yml
server:
  port: 8080
  error:
    include-message: always

spring:
  application:
    name: news-service
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
  data:
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
      username: ${REDIS_USERNAME:userdev}
      password: ${REDIS_PASSWORD:pass123}
````

Explicaci√≥n:

- `spring.kafka.bootstrap-servers`: indica la direcci√≥n de los `brokers de Kafka`. Si la variable de entorno
  `KAFKA_BOOTSTRAP_SERVERS` no es definida, por defecto usar√° la direcci√≥n `localhost:9092`.
- `spring.data.redis`: define las credenciales de acceso a `Redis`. Tambi√©n definimos valores por defecto si las
  variables de entorno no son definidas.

## Configuraci√≥n de Producer y Topic en Kafka

Para que el `News Service` pueda publicar mensajes en `Kafka`, es necesario configurar un `Producer` y definir el
`Topic` donde se enviar√°n dichos mensajes.

A continuaci√≥n, se muestran las clases de configuraci√≥n:

### Configuraci√≥n del Producer

En esta clase se define el `ProducerFactory` y el `KafkaTemplate`.

- El `ProducerFactory` se encarga de crear instancias de productores con las propiedades definidas.
- El `KafkaTemplate` es el componente que abstrae y simplifica el env√≠o de mensajes a `Kafka`.

````java

@Configuration
public class KafkaProducerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    // Propiedades del Producer
    public Map<String, Object> producerConfig() {
        Map<String, Object> props = new HashMap<>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, this.bootstrapServers);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return props;
    }

    // Crea el ProducerFactory
    @Bean
    public ProducerFactory<String, String> producerFactory() {
        return new DefaultKafkaProducerFactory<>(this.producerConfig());
    }

    // Define el KafkaTemplate para enviar mensajes
    @Bean
    public KafkaTemplate<String, String> kafkaTemplate(ProducerFactory<String, String> producerFactory) {
        return new KafkaTemplate<>(producerFactory);
    }
}
````

### Definiendo constantes

En esta clase de utilidad creamos las constantes que estaremos usando en nuestra aplicaci√≥n.

````java

@UtilityClass
public class Constants {
    public static final String TOPIC_NAME = "news-topic";
    public static final String DATE_FORMAT = "^\\d{4}-\\d{2}-\\d{2}$";
    public static final String DATE_NOT_BLANK_MESSAGE = "El par√°metro de solicitud de fecha no puede estar vac√≠o o nulo";
    public static final String DATE_PATTERN_MESSAGE = "La fecha debe estar en el formato yyyy-MM-dd";
    public static final String DATA_FOUND_MESSAGE = "Datos encontrados";
    public static final String DATA_NOT_FOUND_MESSAGE = "La noticia solicitada para la fecha [%s] a√∫n no est√° disponible. Por favor, intente nuevamente en unos momentos";
}
````

### Configuraci√≥n del Topic

En esta clase se define el topic `news-topic`, el cual ser√° creado autom√°ticamente al iniciar la aplicaci√≥n si no
existe en el cluster de `Kafka`.

````java

@Configuration
public class KafkaTopicConfig {
    @Bean
    public NewTopic generateTopic() {
        return TopicBuilder.name(Constants.TOPIC_NAME).build();
    }
}
````

> üìå `Nota`: Esta configuraci√≥n es suficiente para entornos de desarrollo o pruebas. En entornos productivos, es
> recomendable especificar expl√≠citamente el `n√∫mero de particiones` y `r√©plicas` para garantizar escalabilidad y
> tolerancia a fallos.

## Ejemplo de respuesta JSON del servicio externo (Mediastack)

El servicio externo `Mediastack`, que consumiremos en el `worker-service`, nos retorna la siguiente estructura
JSON cuando realizamos la consulta a su API, pas√°ndole din√°micamente el par√°metro `date`:

````bash
$ https://api.mediastack.com/v1/news?access_key=922887e602f7b3a4cdebdd6b3fd7a2c6&limit=5&countries=pe&date=2025-09-22
````

````json
{
  "pagination": {
    "limit": 5,
    "offset": 0,
    "count": 5,
    "total": 128
  },
  "data": [
    {
      "author": "Paolo Valdivia",
      "title": "‚ÄúThe Mandalorian and Grogu‚Äù: Primer tr√°iler oficial",
      "description": "Disney y Lucasfilm lanzaron el primer tr√°iler de ‚ÄúThe Mandalorian and Grogu‚Äù, la pel√≠cula que traer√° de regreso a Pedro Pascal como Din Djarin junto a Grogu. El filme, dirigido por Jon Favreau, se estrena el 22 de mayo de 2026 y ya revel√≥ reparto, trama y sorpresas para los fans de Star Wars.",
      "url": "https://elcomercio.pe/saltar-intro/noticias/the-mandalorian-and-grogu-primer-trailer-oficial-star-wars-noticia/",
      "source": "elcomercio",
      "image": "https://elcomercio.pe/resizer/v2/JZHCGGFOWVC3FFD7NWQCTFP4KA.webp?width=3840&height=2160&auth=717b4ff9458d46d4cfdada7e0117f2b272718725c83b1be44e44c185e1e6994b&smart=true",
      "category": "general",
      "language": "es",
      "country": "pe",
      "published_at": "2025-09-22T16:31:56+00:00"
    },
    {
      "author": "Diego Aquino (Lab Universitario EC)",
      "title": "Obesidad infantil ya supera al bajo peso en el mundo y amenaza a m√°s de un mill√≥n de ni√±os en el Per√∫",
      "description": "UNICEF advierte que m√°s de un mill√≥n de ni√±os peruanos vivir√°n con obesidad en 2030. Hoy, 4 de cada 10 escolares ya presentan exceso de peso.",
      "url": "https://elcomercio.pe/lima/sucesos/obesidad-infantil-en-peru-4-de-cada-10-escolares-en-riesgo-noticia/",
      "source": "elcomercio",
      "image": "https://elcomercio.pe/resizer/v2/6KV22BVQPZHSHOIMVLVQC7CRA4.jpg?width=600&height=315&auth=927e0c04ae20bc41a5dacbfc0c403574b027bf498b98e7d5dbdda0f3bedee214&smart=true",
      "category": "general",
      "language": "es",
      "country": "pe",
      "published_at": "2025-09-22T16:22:00+00:00"
    },
    {
      "author": "Pierina Denegri Davies",
      "title": "¬øViajas a Santiago de Chile? Provecho recorri√≥ la ciudad y arm√≥ una gu√≠a para saborear lo mejor de su cocina",
      "description": "Erizos, centolla, completos, chorrillanas y m√°s: una gu√≠a de restaurantes y espacios para comer bien y variado en la capital chilena.",
      "url": "https://elcomercio.pe/provecho/tendencias/donde-comer-en-santiago-de-chile-restaurantes-brunchs-y-sabores-locales-que-valen-la-pena-noticia/",
      "source": "elcomercio",
      "image": "https://elcomercio.pe/resizer/v2/QDKXN6JJHRFGFC5NUVG45UXNAM.png?width=1200&height=810&auth=9b75dc5875e9bd88aecee6a913b73c7d87527397b914b2c206eb89ef9ddf4f62&smart=true",
      "category": "general",
      "language": "es",
      "country": "pe",
      "published_at": "2025-09-22T16:17:03+00:00"
    },
    {
      "author": "Pierina Denegri Davies",
      "title": "De la TV a una casona en Bellavista: as√≠ es Lote 10, el huarique donde el chef Israel Laura logr√≥ su reencuentro con la cocina",
      "description": "En una casa familiar convertida en restaurante, el chef Israel Laura busca ofrecer una variada oferta de preparaciones suculentas. Conchas al miso, patito parrillero y una cata de piscos son parte de la experiencia que te invitamos a conocer en esta nota.",
      "url": "https://elcomercio.pe/provecho/restaurantes/lote-10-el-huarique-donde-el-chef-israel-laura-explora-su-amor-por-la-gastronomia-y-el-pisco-callao-noticia/",
      "source": "elcomercio",
      "image": "https://elcomercio.pe/resizer/v2/XDJ4HQT6RBGNTPFOJU7HWIMV5Y.png?width=1200&height=810&auth=fe400f43e2a8f9b879497bdd84600b9015759e7ab8f097cd57cf76f4af029069&smart=true",
      "category": "general",
      "language": "es",
      "country": "pe",
      "published_at": "2025-09-22T16:16:45+00:00"
    },
    {
      "author": "Redacci√≥n Diario Correo",
      "title": "Cusco: suspenden trenes entre Cusco y Ollantaytambo por paro en Anta",
      "description": "Cusco: suspenden trenes entre Cusco y Ollantaytambo por paro en Anta",
      "url": "https://diariocorreo.pe/edicion/cusco/cusco-suspenden-trenes-entre-cusco-y-ollantaytambo-por-paro-en-anta-noticia/",
      "source": "diariocorreo",
      "image": "https://diariocorreo.pe/resizer/v2/UBZBU772ANCF7E3OSGCHOJCS6I.jpg?width=1200&height=804&auth=1eae6fafa0405fbbab774b2fe29a2684cb296faac59ffb4d1e6676cdeebf94c6&smart=true",
      "category": "general",
      "language": "es",
      "country": "pe",
      "published_at": "2025-09-22T16:12:56+00:00"
    }
  ]
}
````

`Nota`: este JSON ser√° almacenado en `Redis` (por el `worker-service`) y posteriormente consumido desde el
`news-service`.

## Definici√≥n de DTOs para mapear la respuesta

A partir de la estructura anterior definimos los siguientes DTOs, que representan de manera tipada la informaci√≥n:

````java
public record Pagination(int limit,
                         int offset,
                         int count,
                         int total) {
}
````

````java
public record NewsItem(String author,
                       String title,
                       String description,
                       String url,
                       String source,
                       String image,
                       String category,
                       String language,
                       String country,
                       @JsonProperty("published_at")
                       String publishedAt) {
}
````

````java
public record NewsResponse(Pagination pagination,
                           @JsonProperty("data")
                           List<NewsItem> items) {
}
````

De esta forma queda claro:

- El ejemplo real del JSON externo.
- El prop√≥sito (`Redis` + `consumo en otro servicio`).
- La representaci√≥n tipada en DTOs.

## Configuraci√≥n de Redis en `news-service`

En el `News Service` usamos `Spring Data Redis (reactive)` con `Lettuce` para interactuar con `Redis` de forma
no bloqueante ‚Äî ideal cuando trabajamos con `Spring WebFlux`.

En esta configuraci√≥n tipamos el `ReactiveRedisOperations` con el DTO `NewsResponse`
(la estructura que recibimos de la API externa), de modo que `Redis` almacene y devuelva objetos fuertemente tipados
(`JSON`).

````java

@Configuration
public class RedisConfig {
    @Value("${spring.data.redis.host}")
    private String redisHost;

    @Value("${spring.data.redis.port}")
    private Integer redisPort;

    @Value("${spring.data.redis.username}")
    private String redisUsername;

    @Value("${spring.data.redis.password}")
    private String redisPassword;

    // Configuraci√≥n de conexi√≥n
    @Bean("reactiveRedisConnectionFactory")
    public ReactiveRedisConnectionFactory reactiveRedisConnectionFactory() {
        var config = new RedisStandaloneConfiguration();
        config.setHostName(Objects.requireNonNull(this.redisHost));
        config.setPort(Objects.requireNonNull(this.redisPort));
        config.setUsername(Objects.requireNonNull(this.redisUsername));
        config.setPassword(Objects.requireNonNull(this.redisPassword));
        return new LettuceConnectionFactory(config);
    }

    // Configuraci√≥n del template reactivo con serializadores
    @Bean
    public ReactiveRedisOperations<String, NewsResponse> reactiveRedisOperations(@Qualifier("reactiveRedisConnectionFactory") ReactiveRedisConnectionFactory factory) {
        // Serializer para valores (NewsResponse -> JSON)
        var valueSerializer = new Jackson2JsonRedisSerializer<>(NewsResponse.class);

        // Serializer para las keys (strings legibles en Redis)
        var keySerializer = new StringRedisSerializer();

        var context = RedisSerializationContext.<String, NewsResponse>newSerializationContext(keySerializer)
                .value(valueSerializer)
                .hashKey(keySerializer)
                .hashValue(valueSerializer)
                .build();

        return new ReactiveRedisTemplate<>(factory, context);
    }
}
````

Explicaci√≥n paso a paso

1. `Propiedades externas`
    - `spring.data.redis.host` ‚Üí Direcci√≥n del servidor Redis.
    - `spring.data.redis.port` ‚Üí Puerto de Redis.
    - `spring.data.redis.username` ‚Üí Usuario ACL configurado en Redis.
    - `spring.data.redis.password` ‚Üí Contrase√±a (si est√° configurada en Redis).

   Estas propiedades se inyectan desde el `application.yml`.

2. `ReactiveRedisConnectionFactory`
    - Se crea una instancia de `RedisStandaloneConfiguration` para indicar `host`, `puerto`, `username` y `password`.
    - Se usa `LettuceConnectionFactory`, que es el driver por defecto recomendado para `Redis` en entornos reactivos.
    - Este `ConnectionFactory` ser√° la encargada de abrir conexiones reactivas hacia Redis.
   > `Spring Boot` crea autom√°ticamente un bean llamado `redisConnectionFactory` como parte de su autoconfiguraci√≥n.
   > Al definir nuestro propio bean `reactiveRedisConnectionFactory`, se generan dos candidatos del mismo tipo, lo que
   > provoca ambig√ºedad al momento de inyectarlos. Para resolverlo, usamos:
   >
   > - `@Bean("reactiveRedisConnectionFactory")`: asigna un nombre expl√≠cito al bean personalizado.
   > - `@Qualifier("reactiveRedisConnectionFactory")`: indica claramente cu√°l bean debe inyectarse en
       `reactiveRedisOperations`.
   >
   > Esto evita conflictos y garantiza que se use la configuraci√≥n reactiva definida por nosotros, en lugar de la
   > conexi√≥n est√°ndar que Spring crea por defecto.


3. `ReactiveRedisOperations`
    - Usamos en `ReactiveRedisOperations<String, NewsResponse>` el `NewsResponse` en lugar de `Object`.
    - Ventajas: tipado fuerte, sin cast en las capas superiores, mejor legibilidad y seguridad en tiempo de compilaci√≥n.
    - `Jackson2JsonRedisSerializer<NewsResponse>` ‚Üí serializa los `valores` como `JSON` (y deserializa al leer).
    - `StringRedisSerializer` para las `keys` ‚Üí las claves en `Redis` ser√°n legibles (`news:2025-09-22` por ejemplo) en
      lugar de serializaciones binarias/JSON.

4. `Compatibilidad con worker-service (Redisson)`
    - Para que el `worker-service` (que usa `Redisson`) y el `news-service` (que usa `Spring Data Redis`) sean
      interoperables sobre la misma clave/valor en `Redis`, ambos deben usar JSON y el mismo formato de serializaci√≥n.
    - En `Redisson` configura `TypedJsonJacksonCodec(NewsResponse.class)` o `JsonJacksonCodec` para que `Redisson`
      escriba JSON compatible con `Jackson` en `Spring Data Redis`.

En pocas palabras:

- `Keys` ‚Üí guardadas como String.
- `Values` ‚Üí guardados en formato JSON (gracias a `Jackson`).

## Creaci√≥n del DAO para acceder a Redis

Para mantener una separaci√≥n clara entre la l√≥gica de negocio y el acceso a datos, se implementa un
`DAO (Data Access Object)` que encapsula las operaciones contra `Redis`. De esta forma, la aplicaci√≥n puede
interactuar con la cach√© sin acoplarse directamente a la `API` de `ReactiveRedisOperations`.

### Interfaz NewsDao

La interfaz define las operaciones disponibles para acceder a las noticias en `Redis`. En este caso, √∫nicamente se
consulta si existe una noticia asociada a una fecha espec√≠fica.

````java
public interface NewsDao {
    Mono<NewsResponse> getNews(String date);
}
````

- `Mono<NewsResponse>` ‚Üí dado que estamos en un contexto reactivo, el m√©todo devuelve un `Mono`, que representa un
  valor as√≠ncrono (puede contener la noticia o estar vac√≠o si no existe en `Redis`).
- `String date` ‚Üí se usa la fecha como parte de la clave en `Redis`.

### Implementaci√≥n NewsDaoImpl

La implementaci√≥n utiliza el `ReactiveRedisOperations<String, NewsResponse>` configurado previamente para interactuar
con `Redis` de manera tipada.

````java

@RequiredArgsConstructor
@Repository
public class NewsDaoImpl implements NewsDao {

    private final ReactiveRedisOperations<String, NewsResponse> reactiveRedisOperations;
    private static final String KEY_NEWS_REDIS = "news:%s";

    @Override
    public Mono<NewsResponse> getNews(String date) {
        return this.reactiveRedisOperations.opsForValue().get(KEY_NEWS_REDIS.formatted(date));
    }

}
````

- `@Repository` ‚Üí marca la clase como componente de acceso a datos.
- `@RequiredArgsConstructor (Lombok)` ‚Üí genera autom√°ticamente un constructor con los argumentos final, en este caso
  `reactiveRedisOperations`.
- `ReactiveRedisOperations<String, NewsResponse>` ‚Üí est√° tipado con `NewsResponse`, lo que permite trabajar directamente
  con el DTO sin necesidad de casting ni p√©rdida de informaci√≥n en la serializaci√≥n.
- `KEY_NEWS_REDIS` ‚Üí define un namespace en Redis (`news:<fecha>`), lo que organiza mejor las claves y previene posibles
  colisiones con otros datos.
- `opsForValue().get(KEY_NEWS_REDIS.formatted(date))` ‚Üí recupera el valor de Redis seg√∫n la clave construida. Por
  ejemplo: `news:2025-09-16`.

En pocas palabras:

- Clave en Redis ‚Üí `news:<fecha>`
- Valor en Redis ‚Üí instancia de `NewsResponse` serializada en `JSON`

## Servicio de Noticias (`NewsService`)

El servicio se encarga de:

1. Consultar `Redis` para ver si la noticia solicitada ya est√° disponible.
2. Si la encuentra `(cache HIT)` ‚Üí devolverla al cliente.
3. Si no existe `(cache MISS)` ‚Üí publicar un mensaje en `Kafka` para que el `worker-service` procese la solicitud y
   obtenga la noticia desde la API externa.

### Interfaz

````java
public interface NewsService {
    Mono<NewsResponse> getNews(String date);

    Mono<Void> publishToMessageBroker(String date);
}
````

- `getNews(String date)`: consulta si existe la noticia en `Redis`, y si no, dispara el flujo de publicaci√≥n a `Kafka`.
- `publishToMessageBroker(String date)`: env√≠a un mensaje al `topic` de `Kafka` con la fecha solicitada.

### Implementaci√≥n

````java

@Slf4j
@RequiredArgsConstructor
@Service
public class NewsServiceImpl implements NewsService {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final NewsDao newsDao;

    @Override
    public Mono<NewsResponse> getNews(String date) {
        return this.newsDao.getNews(date)
                .doOnNext(value -> log.info("Cache HIT - Obteniendo desde Redis para fecha: {}", value))
                .switchIfEmpty(Mono.defer(() -> {
                    log.info("Cache MISS - Publicando fecha {} en Kafka", date);
                    return this.publishToMessageBroker(date);
                }));
    }

    @Override
    public Mono<Void> publishToMessageBroker(String date) {
        Message<String> message = MessageBuilder
                .withPayload(date)
                .setHeader(KafkaHeaders.TOPIC, Constants.TOPIC_NAME)
                .build();
        return Mono.fromFuture(() -> this.kafkaTemplate.send(message))
                .then();
    }
}
````

Explicaci√≥n del flujo

1. `newsDao.getNews(date)` ‚Üí busca la noticia en Redis.
2. Si existe:
    - Se loguea `Cache HIT`.
    - Se devuelve directamente el valor encontrado.
3. Si no existe:
    - Se loguea Cache MISS.
    - Se invoca `publishToMessageBroker(date)`, que construye un mensaje y lo env√≠a a `Kafka`.

## üß≠ Cat√°logo de errores de negocio en APIs (`ErrorCatalog`)

En arquitecturas modernas de backend, especialmente en APIs REST, es com√∫n complementar los c√≥digos HTTP est√°ndar
con un `cat√°logo de errores de negocio`. Este cat√°logo permite identificar con precisi√≥n el origen del error, facilitar
la trazabilidad en observabilidad, y ofrecer mensajes claros y consistentes a los consumidores de la API.

### üéØ Prop√≥sito del cat√°logo

El `enum` `ErrorCatalog` centraliza los errores que pueden ocurrir en la l√≥gica de negocio o en validaciones
espec√≠ficas. Cada entrada del cat√°logo contiene:

- `code`: Identificador √∫nico del error, siguiendo una convenci√≥n definida por el equipo (e.g. `NEWS_MS_001`).
- `message`: Descripci√≥n legible del error, √∫til para mostrar al cliente o registrar en logs.

Esto permite desacoplar los errores t√©cnicos del protocolo HTTP de los errores funcionales del dominio.

### üß± Ejemplo de implementaci√≥n

````java

@Getter
@RequiredArgsConstructor
public enum ErrorCatalog {

    // Errores de validaci√≥n
    INVALID_PARAMETERS("NEWS_MS_001", "Par√°metro de solicitud de fecha no v√°lido"),

    // Errores de negocio
    NEWS_NOT_FOUND("NEWS_MS_201", "Noticia no encontrada"),

    // Errores internos del servidor
    INTERNAL_SERVER_ERROR("NEWS_MS_002", "Error Interno del Servidor");

    private final String code;
    private final String message;
}
````

### üîç Diferencias entre errores HTTP y errores de negocio

| Aspecto                        | C√≥digo HTTP (`400`, `500`, etc.) | C√≥digo de cat√°logo (`NEWS_MS_001`)             |
|--------------------------------|----------------------------------|------------------------------------------------|
| Prop√≥sito                      | Indicar tipo de error t√©cnico    | Identificar error espec√≠fico de negocio        |
| Granularidad                   | Limitada                         | Detallada y extensible                         |
| Trazabilidad en observabilidad | Dif√≠cil de rastrear sin contexto | F√°cil de rastrear en logs, dashboards, alertas |
| Mensaje para el cliente        | Gen√©rico                         | Personalizados y claros                        |
| Mantenibilidad                 | No versionable                   | Versionable y documentable                     |

### üì¶ Ejemplo de respuesta en API

Esta estructura puede acompa√±ar un c√≥digo `HTTP 400 Bad Request`, pero el code interno permite identificar el error
exacto en dashboards, logs o alertas.

````json
{
  "code": "NEWS_MS_001",
  "message": "Par√°metro de solicitud de fecha no v√°lido"
}
````

### üõ†Ô∏è Buenas pr√°cticas de dise√±o

- `Convenci√≥n de c√≥digos`: Usa prefijos por m√≥dulo (NEWS_MS, USER_MS, etc.) y numeraci√≥n secuencial.
- `Centralizaci√≥n`: Mant√©n el cat√°logo en un √∫nico enum o agr√∫palo por dominio si crece demasiado.
- `Versionado`: Documenta los cambios en el cat√°logo para evitar rupturas en clientes.
- `Integraci√≥n con observabilidad`: Exp√≥n el code en logs estructurados, trazas y m√©tricas.
- `Mensajes legibles`: Evita mensajes t√©cnicos cr√≠pticos, prioriza claridad para el consumidor.

## DTOs de Respuesta

Para garantizar que la API tenga un contrato consistente tanto en respuestas exitosas como en errores, definimos los
siguientes DTOs:

### 1. Tipos de Error (ErrorType)

- `FUNCTIONAL` ‚Üí Por ejemplo, cuando un par√°metro no es v√°lido o una noticia solicitada no existe.
- `SYSTEM` ‚Üí Por ejemplo, fallas en la comunicaci√≥n con `Kafka`, `Redis`, o errores internos inesperados.

````java
public enum ErrorType {
    FUNCTIONAL, // Errores relacionados con reglas de negocio
    SYSTEM      // Errores relacionados con el sistema o infraestructura
}
````

### 2. Respuesta exitosa (DataResponse)

````java
public record DataResponse<T>(String message,
                              Boolean status,
                              @JsonInclude(JsonInclude.Include.NON_NULL)
                              T data) {
}
````

- `message` ‚Üí mensaje gen√©rico para el cliente (ej: "Operaci√≥n exitosa").
- `status` ‚Üí indica si la operaci√≥n fue correcta (true/false).
- `data` ‚Üí el contenido real de la respuesta (puede ser un DTO, lista, etc.).
- ‚ö†Ô∏è `Si data es null`, no se incluye en el JSON gracias a `@JsonInclude(JsonInclude.Include.NON_NULL)`.

### 3. Respuesta de error (ErrorResponse)

````java
public record ErrorResponse(String code,
                            String message,
                            ErrorType errorType,
                            List<String> details,
                            LocalDateTime timestamp) {
}
````

- `code` ‚Üí c√≥digo de error definido en el cat√°logo (`NEWS_MS_001`, `NEWS_MS_002`, etc.).
- `message` ‚Üí descripci√≥n breve y clara del error.
- `errorType` ‚Üí indica si es un error `FUNCTIONAL` o `SYSTEM`.
- `details` ‚Üí lista de detalles adicionales (ej. campos inv√°lidos).
- `timestamp` ‚Üí momento exacto en que ocurri√≥ el error.

### ‚úÖ Beneficios de este dise√±o

- Estandariza las respuestas, tanto exitosas como de error.
- Facilita el consumo de la API, ya que el cliente sabe siempre qu√© campos esperar.
- Permite extender f√°cilmente la estructura (ej. agregar un campo de requestId en el futuro para trazabilidad).

## Excepciones personalizadas

En la aplicaci√≥n definimos excepciones propias para representar errores de negocio de forma clara y controlada. Esto
permite separar los errores funcionales de los errores t√©cnicos, y facilitar el manejo centralizado de excepciones en
la capa de controladores.

### 1. Excepci√≥n espec√≠fica: `NewsNotFoundException`

````java
public class NewsNotFoundException extends RuntimeException {
    public NewsNotFoundException(String date) {
        super(Constants.DATA_NOT_FOUND_MESSAGE.formatted(date));
    }
}
````

- Extiende de `RuntimeException`, lo que la hace no chequeada `(unchecked)`.
- Se lanza cuando una noticia no existe ni en `Redis` ni en la `API externa`.
- Usa el mensaje predefinido en `Constants.DATA_NOT_FOUND_MESSAGE`, formateado con la fecha solicitada.

### 2. F√°brica de excepciones: `ApplicationExceptions`

````java

@NoArgsConstructor(access = AccessLevel.PRIVATE)
public class ApplicationExceptions {
    public static <T> Mono<T> newsNotFound(String date) {
        return Mono.error(() -> new NewsNotFoundException(date));
    }
}
````

- Clase utilitaria y est√°tica (constructor privado) para centralizar la creaci√≥n de errores en formato reactivo
  `(Mono.error)`.
- `newsNotFound(String date)` retorna un `Mono.error` que emite la excepci√≥n `NewsNotFoundException`.

### ‚úÖ Beneficios de este enfoque

- Separa las excepciones de negocio (`NewsNotFound`) de los errores t√©cnicos.
- Estandariza la forma en que se generan errores reactivos (`ApplicationExceptions`).
- Facilita el futuro manejo global con un `@RestControllerAdvice`, devolviendo un `ErrorResponse` consistente al
  cliente.

## Lanzando excepci√≥n en servicio `NewsServiceImpl`

Cuando una noticia no se encuentra en `Redis`, ocurren dos acciones encadenadas:

1. Se publica un mensaje en el topic de `Kafka`, para que el `worker-service` procese la solicitud.
2. Se lanza una excepci√≥n `NewsNotFoundException`, que posteriormente ser√° capturada por nuestro handler global de
   errores y devuelta al cliente en un formato consistente (`ErrorResponse`).

De esta forma:

- El cliente recibe una respuesta inmediata, sin quedar bloqueado esperando a `Kafka`.
- El `worker-service` se encarga en segundo plano de consultar la API externa y guardar el resultado en `Redis` para
  futuras peticiones.

````java

@Slf4j
@RequiredArgsConstructor
@Service
public class NewsServiceImpl implements NewsService {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final NewsDao newsDao;

    @Override
    public Mono<NewsResponse> getNews(String date) {
        return this.newsDao.getNews(date)
                .doOnNext(value -> log.info("Cache HIT - Obteniendo desde Redis para fecha: {}", value))
                .switchIfEmpty(Mono.defer(() -> {
                    log.info("Cache MISS - Publicando fecha {} en Kafka", date);
                    return this.publishToMessageBroker(date) // Cuando termine la publicaci√≥n ‚Üí lanzamos excepci√≥n
                            .then(ApplicationExceptions.newsNotFound(date));
                }));
    }

    @Override
    public Mono<Void> publishToMessageBroker(String date) {
        Message<String> message = MessageBuilder
                .withPayload(date)
                .setHeader(KafkaHeaders.TOPIC, Constants.TOPIC_NAME)
                .build();
        return Mono.fromFuture(() -> this.kafkaTemplate.send(message))
                .then();
    }
}
````

### üîé Puntos clave

- `Mono.defer(...)`: garantiza que la publicaci√≥n en `Kafka` y la excepci√≥n solo se ejecuten si el flujo viene vac√≠o
  (cache miss).
- `.then(ApplicationExceptions.newsNotFound(date))`: asegura que la excepci√≥n se dispare despu√©s de publicar el mensaje.
- Patr√≥n `Cache-Aside + Event-driven`:
    - Si la noticia existe ‚Üí se devuelve directamente desde Redis.
    - Si no existe ‚Üí se dispara el flujo as√≠ncrono y el cliente recibe un mensaje claro de que la solicitud est√° en
      proceso.

## Crea controlador `NewsController`

El controlador expone el endpoint para consultar noticias. Utiliza `NewsService` y retorna un `DataResponse` tipado
para mantener consistencia en las respuestas.

````java

@Slf4j
@RequiredArgsConstructor
@RestController
@RequestMapping(path = "/api/v1/news")
public class NewsController {

    private final NewsService newsService;

    @GetMapping
    public Mono<ResponseEntity<DataResponse<NewsResponse>>> getNews(@NotBlank(message = Constants.DATE_NOT_BLANK_MESSAGE)
                                                                    @Pattern(regexp = Constants.DATE_FORMAT, message = Constants.DATE_PATTERN_MESSAGE)
                                                                    @RequestParam(required = false) String date) {
        return this.newsService.getNews(date)
                .map(newsData -> ResponseEntity.ok(new DataResponse<>(Constants.DATA_FOUND_MESSAGE, Boolean.TRUE, newsData)));
    }

}
````

üîé Puntos clave

- `Validaci√≥n de par√°metros`
    - Aunque el par√°metro `date` es obligatorio desde el punto de vista funcional, se define con `required = false`.
    - Esto permite que `Bean Validation` (`@NotBlank`, `@Pattern`) maneje la validaci√≥n en lugar de que `Spring WebFlux`
      lo rechace autom√°ticamente.
        - Si us√°ramos `required = true` (valor por defecto), cuando no enviemos el par√°metro date en el request,
          `Spring` lanzar√≠a una excepci√≥n antes de que nuestras validaciones con `Bean Validation` pudieran aplicarse.
        - De esta forma tenemos control total sobre los mensajes de error y aseguramos que todas las respuestas se
          devuelvan en un formato consistente (`ErrorResponse`).


- `Respuesta uniforme`. El uso de `DataResponse<T>` estandariza la salida.
    - Si existe la noticia en Redis ‚Üí se devuelve con `status = true` y data poblado.
    - Si no existe ‚Üí se lanza `NewsNotFoundException`, que m√°s adelante manejaremos en un handler global de excepciones
      para devolver un `ErrorResponse`.

## üõ°Ô∏è Manejador global de excepciones

Un `@RestControllerAdvice` nos permite centralizar el manejo de excepciones y devolver respuestas uniformes a los
clientes, siguiendo siempre la misma estructura (`ErrorResponse`).

En este proyecto, tenemos tres escenarios principales:

1. `Errores de validaci√≥n`: cuando los par√°metros enviados al controlador no cumplen las reglas de `Bean Validation`.
2. `Errores de negocio`: cuando la informaci√≥n buscada no se encuentra.
3. `Errores inesperados`: cualquier excepci√≥n no controlada dentro de la aplicaci√≥n.

````java

@Slf4j
@RestControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(HandlerMethodValidationException.class)
    public Mono<ResponseEntity<ErrorResponse>> handleValidationException(HandlerMethodValidationException e) {
        e.getValueResults().forEach(result -> {
            String parameterName = result.getMethodParameter().getParameterName();
            List<String> messageList = result.getResolvableErrors().stream()
                    .map(MessageSourceResolvable::getDefaultMessage)
                    .toList();
            log.warn("{}: {}", parameterName, messageList);
        });
        return this.buildErrorResponse(
                HttpStatus.BAD_REQUEST,
                ErrorCatalog.INVALID_PARAMETERS,
                ErrorType.FUNCTIONAL,
                e.getMessage());
    }

    @ExceptionHandler(NewsNotFoundException.class)
    public Mono<ResponseEntity<ErrorResponse>> handleNewsNotFoundException(NewsNotFoundException e) {
        log.error("{}", e.getMessage(), e);
        return this.buildErrorResponse(
                HttpStatus.NOT_FOUND,
                ErrorCatalog.NEWS_NOT_FOUND,
                ErrorType.FUNCTIONAL,
                e.getMessage());
    }

    @ExceptionHandler(Exception.class)
    public Mono<ResponseEntity<ErrorResponse>> handleGenericException(Exception e) {
        log.error("Excepci√≥n General: {}", e.getMessage(), e);
        return this.buildErrorResponse(
                HttpStatus.INTERNAL_SERVER_ERROR,
                ErrorCatalog.INTERNAL_SERVER_ERROR,
                ErrorType.SYSTEM,
                e.getMessage());
    }

    private Mono<ResponseEntity<ErrorResponse>> buildErrorResponse(HttpStatus status, ErrorCatalog errorCatalog,
                                                                   ErrorType errorType, String details) {
        return Mono.just(ResponseEntity
                .status(status)
                .body(new ErrorResponse(
                        errorCatalog.getCode(),
                        errorCatalog.getMessage(),
                        errorType,
                        Collections.singletonList(details),
                        LocalDateTime.now())
                ));
    }

}
````

- `HandlerMethodValidationException`. Este tipo de excepci√≥n se lanza cuando la validaci√≥n ocurre directamente sobre
  par√°metros simples del m√©todo (por ejemplo, `@RequestParam`) y no se usa `@Validated`.
- üí° Se recomienda incluir los mensajes de validaci√≥n por par√°metro en el cuerpo de la respuesta para facilitar el
  diagn√≥stico desde el cliente.

## üßæ Configura a contenedor de Redis en docker compose

Creamos un archivo `compose.yml` donde definimos el siguiente servicio de redis.

````yml
services:
  s-redis:
    image: redis:8.0.3-alpine
    container_name: c-redis
    restart: unless-stopped
    ports:
      - '6379:6379'
    command: [ "--user userdev >pass123 on allcommands allkeys", "--user default off" ]
````

Esta configuraci√≥n levanta un contenedor `Redis` con:

- Un usuario ACL llamado `userdev` con contrase√±a `pass123`.
- Permisos completos: acceso a todos los comandos (`allcommands`) y todas las claves (`allkeys`).
- El usuario `default` est√° deshabilitado (`default off`) para evitar accesos sin autenticaci√≥n.

üîê Seguridad

- Redis exige autenticaci√≥n desde el arranque.
- Cualquier intento de ejecutar comandos sin `AUTH` resultar√° en `(error) NOAUTH Authentication required.`.
- Ejemplo de autenticaci√≥n desde `redis-cli`:
    ````bash
    127.0.0.1:6379> auth userdev pass123
    OK 
    ````

### Diferencia entre `--user` y `ACL SETUSER`

| Contexto                   | Forma                                                 | ¬øCu√°ndo se usa?                                                                                                                                    |
|----------------------------|-------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|
| Arranque del contenedor    | `--user userdev >pass123 on allcommands allkeys`      | Se usa en el `command` de `Docker Compose` para definir usuarios `ACL` al iniciar `Redis`. Redis interpreta esta l√≠nea como configuraci√≥n inicial. |
| Interacci√≥n en tiempo real | `ACL SETUSER userdev >pass123 on allcommands allkeys` | Se usa dentro de `redis-cli` para crear o modificar usuarios `ACL` din√°micamente mientras `Redis` est√° corriendo.                                  |

Ambas formas son equivalentes en funcionalidad, pero se aplican en contextos distintos: una al iniciar Redis, otra
durante su ejecuci√≥n.

## üßæ [Configura contenedor de Kafka en docker compose](https://docs.docker.com/guides/kafka/)

> Este apartado fue tomado de la siguiente gu√≠a
> [Developing event-driven applications with Kafka and Docker.](https://docs.docker.com/guides/kafka/)

`Apache Kafka`, una plataforma distribuida de streaming de eventos, suele ser la base de las arquitecturas basadas en
eventos. Desafortunadamente, configurar e implementar una instancia propia de `Kafka` para el desarrollo suele ser
complicado. Afortunadamente, `Docker` y los contenedores lo simplifican mucho.

En esta gu√≠a, aprender√° a:

- Usar Docker para iniciar un cl√∫ster de Kafka
- Conectar una aplicaci√≥n no contenedorizada al cl√∫ster
- Conectar una aplicaci√≥n contenedorizada al cl√∫ster

A partir de `Kafka 3.3`, la implementaci√≥n de `Kafka` se simplific√≥ enormemente al prescindir de `Zookeeper` gracias
a `KRaft (Kafka Raft)`. Con `KRaft`, configurar una instancia de `Kafka` para el desarrollo local es mucho m√°s
sencillo. A partir del lanzamiento de `Kafka 3.8`, ya est√° disponible una nueva imagen de Docker nativa de Kafka,
que proporciona un inicio significativamente m√°s r√°pido y un menor consumo de memoria.

> Esta gu√≠a utilizar√° la imagen de `Apache/Kafka`, ya que incluye numerosos scripts √∫tiles para administrar y trabajar
> con `Kafka`. Sin embargo, puede que prefiera usar la imagen nativa de `Apache/Kafka`, ya que se inicia m√°s r√°pido y
> requiere menos recursos.

### Definici√≥n de los listeners

Para que esto sea m√°s claro, veamos c√≥mo debe configurarse `Kafka` para admitir `dos tipos de conexi√≥n`:

1. `Conexiones de host` (aquellas que llegan a trav√©s del puerto asignado al host): estas deben conectarse mediante
   `localhost`.
2. `Conexiones de Docker` (aquellas que provienen de las redes Docker): estas no pueden conectarse mediante `localhost`,
   sino mediante el alias de red (o direcci√≥n DNS) del `servicio de Kafka`.

Dado que los clientes necesitan dos m√©todos diferentes para conectarse, se requieren dos oyentes: `HOST` y `DOCKER`.
El listener `HOST` indicar√° a los clientes que se conecten mediante `localhost:9092`, mientras que el listener `DOCKER`
les indicar√° que se conecten mediante `s-kafka:9093`. Cabe destacar que esto significa que `Kafka` escucha en ambos
puertos, `9092` y `9093`. Sin embargo, solo el listener del host debe estar expuesto al host.

![02.png](assets/02.png)

Para configurar esto, se requiere configuraci√≥n adicional en el archivo `compose.yaml` de `Kafka`. Una vez que se
sobrescriban algunos valores predeterminados, tambi√©n se deben especificar otras opciones para que el modo
`KRaft` funcione.

````yml
services:
  s-kafka:
    image: apache/kafka:4.1.0
    container_name: c-kafka
    restart: unless-stopped
    environment:
      # Settings required for KRaft mode
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9091
      # Configure listeners for both docker and host communication
      KAFKA_LISTENERS: CONTROLLER://localhost:9091,HOST://0.0.0.0:9092,DOCKER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: HOST://localhost:9092,DOCKER://s-kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,DOCKER:PLAINTEXT,HOST:PLAINTEXT
      # Listener to use for broker-to-broker communication
      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER
      # Required for a single node cluster
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - '9092:9092'
````

- `KAFKA_NODE_ID: 1`. Identificador √∫nico del nodo Kafka en el cl√∫ster. En modo `KRaft`, cada nodo debe tener un ID
  distinto.
- `KAFKA_PROCESS_ROLES: broker,controller`. Define los roles que cumple este nodo: `broker` (gestiona mensajes) y
  `controller` (coordina el cl√∫ster). En cl√∫steres peque√±os, ambos roles pueden coexistir.
- `KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER`. Indica qu√© listener se usar√° para la comunicaci√≥n del controller. Debe
  coincidir con uno definido en `KAFKA_LISTENERS`.
- `KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9091`. Define los votantes del quorum del controller. En este caso, un
  solo nodo (ID 1) escuchando en `localhost:9091`. Es obligatorio en modo `KRaft`.


- `KAFKA_LISTENERS: CONTROLLER://localhost:9091,HOST://0.0.0.0:9092,DOCKER://0.0.0.0:9093`. Define los endpoints donde
  Kafka escuchar√° conexiones:
    - `CONTROLLER://localhost:9091`: usado internamente por el controller.
    - `HOST://0.0.0.0:9092`: escucha en todas las interfaces del host, permitiendo que tu aplicaci√≥n en el IDE se
      conecte v√≠a `localhost:9092`.
    - `DOCKER://0.0.0.0:9093`: tambi√©n escucha en todas las interfaces, pero ser√° usado por otros contenedores que
      acceden v√≠a `s-kafka:9093`.
    - ‚ö†Ô∏è El uso de `0.0.0.0` significa ‚Äúescuchar en todas las interfaces disponibles‚Äù, es decir, aceptar conexiones
      desde cualquier IP que est√© conectada al contenedor. Es equivalente a escribir `:9092` o `:9093`.
- `KAFKA_ADVERTISED_LISTENERS: HOST://localhost:9092,DOCKER://s-kafka:9093`. Define c√≥mo Kafka se anuncia a los
  clientes:
    - `HOST://localhost:9092`: para que tu aplicaci√≥n en el IDE se conecte usando `localhost`.
    - `DOCKER://s-kafka:9093`: para que otros contenedores lo encuentren usando el nombre del servicio (`s-kafka`).
- `KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,DOCKER:PLAINTEXT,HOST:PLAINTEXT`. Asocia cada listener
  con el protocolo de seguridad. En este caso, todos usan `PLAINTEXT` (sin `TLS` ni autenticaci√≥n).
- `KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER`. Kafka usar√° el listener `DOCKER` para la comunicaci√≥n interna entre
  brokers. Aunque sea un solo nodo, esta variable es obligatoria en modo `KRaft`.


- `KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1`. Define cu√°ntas r√©plicas tendr√° el t√≥pico de offsets. En cl√∫steres de un
  solo nodo, debe ser 1 para evitar errores de arranque.

### üß≠ Conectividad seg√∫n escenario

- Desde el IDE (host): Usa `bootstrap.servers=localhost:9092`
- Desde otro contenedor: Usa `bootstrap.servers=s-kafka:9093`

## Levantando Redis y Kafka con Docker Compose

Para levantar nuestros servicios con `Docker Compose` ejecutamos el siguiente comando.

````bash
D:\programming\spring\02.youtube\09.dev_dominio\spring-kafka-redis (main -> origin)
$ docker compose -f ./docker/compose.yml up -d                                     
[+] Running 3/3                                                                    
 ‚úî Network docker_default  Created                                                 
 ‚úî Container c-redis       Started                                                 
 ‚úî Container c-kafka       Started                                                 
````

Comprobamos que los contenedores est√°n ejecut√°ndose correctamente.

````bash
$ docker container ls -a
CONTAINER ID   IMAGE                COMMAND                  CREATED         STATUS         PORTS                                         NAMES
f2e32f2f7d80   redis:8.0.3-alpine   "docker-entrypoint.s‚Ä¶"   8 seconds ago   Up 7 seconds   0.0.0.0:6379->6379/tcp, [::]:6379->6379/tcp   c-redis
51ca449a7828   apache/kafka:4.1.0   "/__cacert_entrypoin‚Ä¶"   9 seconds ago   Up 7 seconds   0.0.0.0:9092->9092/tcp, [::]:9092->9092/tcp   c-kafka
````

## üöÄ Ejecuci√≥n y pruebas iniciales del `news-service`

Al levantar la aplicaci√≥n por primera vez, esta se conectar√° a `Redis` y a `Apache Kafka` utilizando los valores por
defecto definidos en el `application.yml`.

El log de arranque confirma que la aplicaci√≥n se inicializ√≥ correctamente y que los clientes de `Redis` y `Kafka`
fueron configurados sin errores:

````bash
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.5)

2025-09-23T16:25:24.661-05:00  INFO 18616 --- [news-service] [           main] d.m.news.app.NewsServiceApplication      : Starting NewsServiceApplication using Java 21.0.6 with PID 18616 (D:\programming\spring\02.youtube\09.dev_dominio\spring-kafka-redis\news-service\target\classes started by magadiflo in D:\programming\spring\02.youtube\09.dev_dominio\spring-kafka-redis)
2025-09-23T16:25:24.666-05:00  INFO 18616 --- [news-service] [           main] d.m.news.app.NewsServiceApplication      : No active profile set, falling back to 1 default profile: "default"
2025-09-23T16:25:25.496-05:00  INFO 18616 --- [news-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
2025-09-23T16:25:25.499-05:00  INFO 18616 --- [news-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-09-23T16:25:25.552-05:00  INFO 18616 --- [news-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 24 ms. Found 0 Redis repository interfaces.
2025-09-23T16:25:27.348-05:00  INFO 18616 --- [news-service] [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	...
	ssl.truststore.type = JKS

2025-09-23T16:25:27.555-05:00  INFO 18616 --- [news-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-09-23T16:25:27.557-05:00  INFO 18616 --- [news-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-09-23T16:25:27.557-05:00  INFO 18616 --- [news-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1758662727552
2025-09-23T16:25:28.134-05:00  INFO 18616 --- [news-service] [service-admin-0] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for news-service-admin-0 unregistered
2025-09-23T16:25:28.146-05:00  INFO 18616 --- [news-service] [service-admin-0] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-09-23T16:25:28.146-05:00  INFO 18616 --- [news-service] [service-admin-0] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-09-23T16:25:28.146-05:00  INFO 18616 --- [news-service] [service-admin-0] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-09-23T16:25:28.259-05:00  INFO 18616 --- [news-service] [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 8080 (http)
2025-09-23T16:25:28.273-05:00  INFO 18616 --- [news-service] [           main] d.m.news.app.NewsServiceApplication      : Started NewsServiceApplication in 4.407 seconds (process running for 5.127) 
````

### üîé Prueba del endpoint REST

Realizamos una petici√≥n al endpoint del `news-service` para obtener la noticia correspondiente a una fecha espec√≠fica:

````bash
$ curl -v http://localhost:8080/api/v1/news?date=2025-09-23 | jq
>
< HTTP/1.1 404 Not Found
< Content-Type: application/json
< Content-Length: 259
<
{
  "code": "NEWS_MS_201",
  "message": "Noticia no encontrada",
  "errorType": "FUNCTIONAL",
  "details": [
    "La noticia solicitada para la fecha [2025-09-23] a√∫n no est√° disponible. Por favor, intente nuevamente en unos momentos"
  ],
  "timestamp": "2025-09-23T16:27:21.8896657"
}
````

La respuesta confirma que la noticia a√∫n no existe en `Redis`, y la aplicaci√≥n devuelve el mensaje funcional
correspondiente.

### üì© Validaci√≥n en Kafka

Aunque la noticia no estaba disponible, el servicio public√≥ la fecha solicitada en el topic `news-topic`. Esto puede
verificarse con el consumidor de consola:

````bash
$ docker container exec -it c-kafka /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic news-topic --from-beginning
2025-09-23 
````

Esto confirma que la aplicaci√≥n procesa correctamente el flujo esperado:

1. `Consulta en Redis` (no encuentra la noticia).
2. `Publica la fecha en Kafka` para que otro servicio (`worker-service`) la procese.

üìå Conclusi√≥n:
> El `news-service` qued√≥ validado en su primera fase: `Redis` funciona como cach√© de noticias y `Kafka` como canal de
> comunicaci√≥n para delegar el trabajo a otro servicio.

## Creando proyecto: [worker-service](https://start.spring.io/#!type=maven-project&language=java&platformVersion=3.5.5&packaging=jar&jvmVersion=21&groupId=dev.magadiflo&artifactId=worker-service&name=worker-service&description=Demo%20project%20for%20Spring%20Boot&packageName=dev.magadiflo.worker.app&dependencies=webflux,lombok,kafka)

El `worker-service` est√° construido con `Spring Boot 3.5.5` y `Java 21`. Su rol principal es
`consumir fechas desde Kafka`, `consultar noticias al servicio externo` y `almacenarlas en Redis` utilizando `Redisson`.

````xml
<!--Spring Boot 3.5.5-->
<!--Java 21-->
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-webflux</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>

    <!--Agregado manualmente: Cliente Redisson (para conexi√≥n a Redis)-->
    <dependency>
        <groupId>org.redisson</groupId>
        <artifactId>redisson-spring-boot-starter</artifactId>
        <version>3.51.0</version>
    </dependency>
    <!--/Agregado manualmente-->
    <dependency>
        <groupId>org.projectlombok</groupId>
        <artifactId>lombok</artifactId>
        <optional>true</optional>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-test</artifactId>
        <scope>test</scope>
    </dependency>
    <dependency>
        <groupId>io.projectreactor</groupId>
        <artifactId>reactor-test</artifactId>
        <scope>test</scope>
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka-test</artifactId>
        <scope>test</scope>
    </dependency>
</dependencies>
````

Nota

En este microservicio `no usaremos` `Spring Data Redis Reactive` (como hicimos en `news-service`), sino que
integraremos `Redis` mediante `redisson-spring-boot-starter`.

La elecci√≥n de `Redisson` se debe a que:

- Proporciona un cliente `Redis` altamente optimizado y no bloqueante.
- Ofrece una API m√°s rica que la de `Spring Data Redis` (ejemplo: `RMap`, `RBucket`, `RList`, `locks distribuidos`,
  `sem√°foros`, etc.).
- Facilita definir el tipo de dato que se `serializa/deserializa` en `Redis` mediante codecs como
  `TypedJsonJacksonCodec`.
- Permite explorar un enfoque alternativo de integraci√≥n con `Redis`, lo que complementa la experiencia del curso.
- Adem√°s, forma parte de mi experiencia previa: realic√© un curso de `Redis` donde se utiliz√≥ `Redisson` y me interesa
  poner en pr√°ctica lo aprendido. Para referencia, aqu√≠ est√° el enlace al curso:
  [reactive-redis-masterclass](https://github.com/magadiflo/reactive-redis-masterclass).

Esto nos permitir√° comparar ambos enfoques (`Spring Data Redis` vs. `Redisson`) y entender mejor sus fortalezas en
distintos escenarios.

## Configurando `application.yml`

En el archivo `application.yml` del proyecto `worker-service` definimos las configuraciones base de la aplicaci√≥n.
Adem√°s, a√±adimos propiedades personalizadas para `Redisson`, que utilizaremos para establecer la conexi√≥n con `Redis`.

````yml
server:
  port: 8081
  error:
    include-message: always

spring:
  application:
    name: worker-service
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}

redisson:
  host: ${REDIS_HOST:localhost}
  port: ${REDIS_PORT:6379}
  username: ${REDIS_USERNAME:userdev}
  password: ${REDIS_PASSWORD:pass123}
````

Con esto:

- La aplicaci√≥n se ejecutar√° en el puerto `8081`.
- Definimos el nombre de la aplicaci√≥n como `worker-service`.
- Configuramos el `bootstrap server` de `Kafka`, con la opci√≥n de sobreescribirlo a trav√©s de variables de entorno.
- Creamos un bloque de propiedades personalizadas bajo la clave `redisson`, que luego utilizaremos en una clase de
  configuraci√≥n para inicializar nuestro `RedissonClient` y `RedissonReactiveClient`.

## ‚öôÔ∏è Configurando Redisson en `worker-service`

En este microservicio usaremos `Redisson` como cliente para conectarnos a `Redis`. Para ello definimos una clase de
configuraci√≥n que registra los `Bean` necesarios.

````java

@Configuration
public class RedisConfig {
    @Value("${redisson.host}")
    private String redisHost;

    @Value("${redisson.port}")
    private Integer redisPort;

    @Value("${redisson.username}")
    private String redisUsername;

    @Value("${redisson.password}")
    private String redisPassword;

    @Bean(destroyMethod = "shutdown")
    public RedissonClient redissonClient() {
        Config config = new Config();
        config.useSingleServer()
                .setAddress("redis://%s:%s".formatted(this.redisHost, this.redisPort))
                .setUsername(this.redisUsername)
                .setPassword(this.redisPassword);
        return Redisson.create(config);
    }

    @Bean
    public RedissonReactiveClient redissonReactiveClient(RedissonClient redissonClient) {
        return redissonClient.reactive();
    }
}
````

- `RedissonClient` ‚Üí expone una API imperativa/sincr√≥nica.
- `RedissonReactiveClient` ‚Üí expone una API no bloqueante y reactiva, construida sobre Reactor, lo que lo hace
  compatible con `Spring WebFlux`.

En resumen:

- `RedissonClient` es el bean principal y obligatorio, porque all√≠ configuramos toda la conexi√≥n hacia Redis (host,
  puerto, credenciales, etc.).
- A partir de este bean, nace el `RedissonReactiveClient`, que simplemente es una "vista reactiva" del cliente base.
- Esto nos permite tener flexibilidad:
    - Si en alg√∫n punto necesitamos usar APIs imperativas, podemos usar directamente `RedissonClient`.
    - Para mantenernos 100% no bloqueantes en `Spring WebFlux`, trabajamos con `RedissonReactiveClient`.

De esta manera, garantizamos:

- üîë Una √∫nica configuraci√≥n centralizada de Redis.
- üöÄ Integraci√≥n fluida con el stack reactivo de Spring.
- ‚úÖ Cierre seguro de recursos (`shutdown` en el `RedissonClient`) cuando la aplicaci√≥n se detiene.

### üîë ¬øPor qu√© usamos `destroyMethod = "shutdown"`?

Al declarar el `RedissonClient` como `@Bean`, `Spring` se encarga de su ciclo de vida. La propiedad
`destroyMethod = "shutdown"` asegura que, cuando la aplicaci√≥n se detenga, `Spring` ejecute autom√°ticamente
`redissonClient.shutdown()`.

Esto es importante porque `Redisson abre recursos que deben cerrarse expl√≠citamente`:

- üîÑ Threads internos (event loops, timers, pool de conexiones).
- üåê Conexiones TCP activas hacia Redis.
- üïë Operaciones pendientes que de lo contrario quedar√≠an colgadas.

Si no cerramos correctamente el cliente:

- ‚ùå Podr√≠amos tener fugas de memoria (memory leaks).
- ‚ùå La aplicaci√≥n podr√≠a tardar en apagarse o incluso quedarse colgada.
- ‚ùå Recursos del sistema (RAM, sockets) quedar√≠an ocupados innecesariamente.

‚úÖ Beneficios de `shutdown()`

Cuando `Spring` invoca `redissonClient.shutdown()`:

- Libera todas las conexiones TCP abiertas.
- Cierra los thread pools creados por Redisson.
- Cancela tareas en ejecuci√≥n o pendientes.
- Limpia recursos internos en memoria.
- Garantiza un apagado limpio de la aplicaci√≥n.

üìå En resumen:

> Es una buena pr√°ctica usar `destroyMethod = "shutdown"` en `RedissonClient`, ya que asegura la liberaci√≥n ordenada
> de recursos, evitando problemas de estabilidad o consumo excesivo de memoria en tu aplicaci√≥n.
>
> Un `memory leak` es cuando tu aplicaci√≥n reserva memoria pero nunca la libera, causando que se acumule basura hasta
> agotar la RAM disponible. Por ejemplo: abres 1000 conexiones a Redis pero nunca las cierras ‚Üí se acumula memoria ‚Üí tu
> app se vuelve lenta o se cuelga.

## ‚öôÔ∏è Configuraci√≥n del Consumer de Kafka

Para que el `worker-service` pueda recibir mensajes desde `Kafka`, necesitamos configurar un `Consumer` que escuche
el topic `news-topic` publicado por el `news-service`.

### Configuraci√≥n del Consumer

````java

@Configuration
public class KafkaConsumerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    private Map<String, Object> consumerConfig() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, this.bootstrapServers);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        return props;
    }

    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        return new DefaultKafkaConsumerFactory<>(this.consumerConfig());
    }

    @Bean
    public KafkaListenerContainerFactory<ConcurrentMessageListenerContainer<String, String>> factory(ConsumerFactory<String, String> consumerFactory) {
        ConcurrentKafkaListenerContainerFactory<String, String> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);
        return factory;
    }
}
````

- `ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG` ‚Üí direcci√≥n del cl√∫ster Kafka.
- `StringDeserializer` ‚Üí convierte los mensajes recibidos desde Kafka en String.
- `ConcurrentKafkaListenerContainerFactory` ‚Üí permite manejar varios consumers en paralelo si se requiere (√∫til para
  escalabilidad).

### Constantes globales para Kafka

Centralizamos valores como el nombre del topic y el groupId en una clase de utilidades. Esto evita duplicaci√≥n y
errores al momento de usar los nombres en distintas clases.

````java

@UtilityClass
public class Constants {

    public static final String TOPIC_NEWS = "news-topic";
    public static final String GROUP_ID_NEWS_TOPIC = "news-consumer-group";
    public static final String DATA_NOT_FOUND_MESSAGE = "La noticia solicitada para la fecha [%s] no existe en el servicio externo";

}
````

- `TOPIC_NEWS` ‚Üí topic donde se publican las fechas desde `news-service`.
- `GROUP_ID_NEWS_TOPIC` ‚Üí identificador del grupo de consumidores que trabajar√° con ese topic.

> Un mismo `groupId` asegura que cada mensaje se procese una sola vez dentro del grupo (aunque haya varios
> consumidores).

### Creaci√≥n del Topic en Kafka

Aunque `Kafka` permite crear topics de forma manual, podemos configurarlo para que Spring los genere autom√°ticamente
si no existen.

````java

@Configuration
public class KafkaTopicConfig {
    @Bean
    public NewTopic generateTopic() {
        return TopicBuilder.name(Constants.TOPIC_NEWS).build();
    }
}
````

- Si el topic ya existe en Kafka ‚Üí esta configuraci√≥n se ignora.
- Si no existe ‚Üí se crea autom√°ticamente con las caracter√≠sticas indicadas.

üìå Resumen r√°pido:

- El `KafkaConsumerConfig` define c√≥mo debe comportarse el consumer.
- La clase `Constants` centraliza configuraciones comunes.
- `KafkaTopicConfig` asegura que el topic `news-topic` est√© disponible al iniciar la aplicaci√≥n, usando `KafkaAdmin` de
  forma autom√°tica.

## ‚öôÔ∏è Configuraci√≥n de WebClient

Para que el `worker-service` pueda comunicarse con el servicio externo `Mediastack`, necesitamos un cliente HTTP
reactivo. En este caso usaremos `WebClient`, que es el cliente no bloqueante que trae `Spring WebFlux`.

### Configuraci√≥n en `application.yml`

Agregamos la configuraci√≥n del servicio externo con su `base-url`. En esta primera versi√≥n la URL est√° hardcodeada,
pero m√°s adelante podr√≠a parametrizarse con variables de entorno.

````yml
external:
  services:
    news:
      base-url: https://api.mediastack.com
````

### Clase de configuraci√≥n

````java

@Configuration
public class WebClientConfig {

    @Value("${external.services.news.base-url}")
    private String externalNewsUrl;

    @Bean
    public WebClient.Builder externalNewsClientBuilder() {
        return WebClient.builder()
                .baseUrl(this.externalNewsUrl);
    }
}
````

üîç Explicaci√≥n

- `@Configuration` ‚Üí indica que esta clase define beans de configuraci√≥n para el contexto de Spring.
- `@Value(...)` ‚Üí inyecta el valor definido en `application.yml`.
- `WebClient.Builder` ‚Üí exponemos un builder en lugar de un `WebClient` directamente, lo que nos da flexibilidad:
    - Podemos personalizar cada instancia (`.defaultHeader(...)`, `.filter(...)`, etc.).
    - Evitamos problemas si m√°s adelante necesitamos m√∫ltiples clientes con diferentes URLs.

## Definiendo dtos para el servicio externo de noticias

Cuando consumimos datos desde un API externa (en este caso desde `mediastack`), necesitamos crear clases que
representen la estructura del `JSON` que recibiremos.

En este proyecto usamos `Java Records`, que son inmutables, concisos y perfectos para este tipo de casos.

DTO `NewsItem`

````java
public record NewsItem(String author,
                       String title,
                       String description,
                       String url,
                       String source,
                       String image,
                       String category,
                       String language,
                       String country,
                       @JsonProperty("published_at")
                       String publishedAt) {
}
````

- Este record representa cada noticia individual.
- Se incluyen propiedades t√≠picas de una noticia: `title`, `description`, `url`, `image`, etc.
- La anotaci√≥n `@JsonProperty("published_at")` es necesaria porque el nombre del campo en el JSON (`published_at`) no
  coincide con la convenci√≥n camelCase en Java (`publishedAt`).

DTO `Pagination`

````java
public record Pagination(int limit,
                         int offset,
                         int count,
                         int total) {
}
````

Representa la secci√≥n de paginaci√≥n que env√≠a el API de noticias, con metadatos como:

- `limit`: cu√°ntos elementos se solicitaron.
- `offset`: desde qu√© posici√≥n inicia la respuesta.
- `count`: cu√°ntos resultados fueron devueltos.
- `total`: total de resultados disponibles.

DTO `NewsResponse`

````java
public record NewsResponse(Pagination pagination,
                           @JsonProperty("data")
                           List<NewsItem> items) {
}
````

Representa la respuesta completa del servicio de noticias:

- Incluye la paginaci√≥n (`pagination`).
- El campo `data` del JSON se mapea a la lista de noticias (`items`) usando `@JsonProperty("data")`.

### ‚úÖ Resumen

- Usamos Java Records para definir DTOs inmutables y concisos.
- `@JsonProperty` nos permite mapear nombres de campos JSON que no cumplen con la convenci√≥n de Java.
- Esta estructura asegura que el `WebClient` pueda deserializar autom√°ticamente las respuestas JSON del servicio externo
  a objetos Java, listos para ser usados en la l√≥gica de negocio.

## Definiendo DAO para persistencia en Redis

En este servicio necesitamos persistir temporalmente la respuesta del API de noticias en `Redis` para:

- Evitar m√∫ltiples llamadas innecesarias al servicio externo.
- Mejorar el rendimiento respondiendo desde cache.
- Controlar la expiraci√≥n de los datos (ej. 1 hora).

Para esto usamos `Redisson Reactive`, que se integra muy bien con `WebFlux`.

### Interfaz `NewsDao`

````java
public interface NewsDao {
    Mono<NewsResponse> getNews(String date);

    Mono<Void> saveNews(String date, NewsResponse response);
}
````

1. `Mono<NewsResponse> getNews(String date)`
    - Recupera una noticia almacenada en Redis, asociada a la clave generada con la fecha indicada.
    - Si no existe la noticia, retornar√° un `Mono.empty()`.
    - Par√°metros:
        - `date`: fecha de las noticias solicitadas, usada como parte de la clave en Redis.
    - Retorno: `Mono<NewsResponse>` con los datos de la noticia, o vac√≠o si no se encuentra.

2. `Mono<Void> saveNews(String date, NewsResponse response)`
    - Persiste la respuesta de noticias en Redis.
    - La clave sigue el patr√≥n `news:{date}`.
    - Usualmente se establece un TTL (ej. 1 hora) para evitar datos obsoletos.
    - Par√°metros:
        - `date`: fecha que forma parte de la clave en Redis.
        - `response`: objeto `NewsResponse` con las noticias a guardar.
    - Retorno: `Mono<Void>` que indica solo √©xito o error (no retorna un valor).

### Implementaci√≥n `NewsDaoImpl`

````java

@Slf4j
@RequiredArgsConstructor
@Repository
public class NewsDaoImpl implements NewsDao {

    private final RedissonReactiveClient client;
    private static final String KEY_NEWS_REDIS = "news:%s";
    private static final TypedJsonJacksonCodec NEWS_CODEC = new TypedJsonJacksonCodec(NewsResponse.class);

    @Override
    public Mono<NewsResponse> getNews(String date) {
        String key = getRedisKey(date);
        log.info("Consultando noticia en Redis con clave: {}", key);

        RBucketReactive<NewsResponse> bucket = this.client.getBucket(key, NEWS_CODEC);
        return bucket.get()
                .doOnNext(newsResponse -> log.info("Noticia encontrada en Redis para fecha: {}", date));
    }

    @Override
    public Mono<Void> saveNews(String date, NewsResponse response) {
        String key = getRedisKey(date);
        log.info("Guardando noticia en Redis con clave: {}", key);

        RBucketReactive<NewsResponse> bucket = this.client.getBucket(key, NEWS_CODEC);
        return bucket.set(response, Duration.ofHours(1L));
    }

    private static String getRedisKey(String date) {
        return KEY_NEWS_REDIS.formatted(date);
    }
}
````

üîé Explicaci√≥n de los elementos clave

- `RedissonReactiveClient`
    - Cliente reactivo de Redisson que permite operaciones no bloqueantes sobre Redis.
    - Inyectado por constructor gracias a `@RequiredArgsConstructor`.

- `KEY_NEWS_REDIS`
    - Plantilla para construir las claves de Redis siguiendo el formato `news:<fecha>`.
    - Facilita mantener consistencia en la nomenclatura de claves.

- `TypedJsonJacksonCodec`
    - Codec que transforma autom√°ticamente entre objetos `NewsResponse` y `JSON`.
    - Evita tener que `serializar/deserializar` manualmente.

- `RBucketReactive`
    - Estructura b√°sica de Redis (clave/valor) adaptada a operaciones reactivas.
    - Ideal para almacenar un √∫nico objeto asociado a cada clave.

‚öôÔ∏è L√≥gica de los m√©todos

1. `getNews(String date)`
    - Construye la clave Redis (`news:<fecha>`).
    - Recupera el objeto asociado usando `RBucketReactive.get()`.
    - Si encuentra datos, loggea el √©xito.
    - Retorna un `Mono<NewsResponse>` que puede estar vac√≠o si no existe valor.
2. `saveNews(String date, NewsResponse response)`
    - Construye la clave Redis (`news:<fecha>`).
    - Almacena la respuesta con un `TTL` de 1 hora (`Duration.ofHours(1L)`).
    - Retorna `Mono<Void>` ‚Üí solo indica `√©xito/error`, no un valor.

## Definiendo Excepciones Personalizadas

En este apartado definimos excepciones espec√≠ficas que representen distintos escenarios de error al interactuar con el
servicio externo de noticias (`mediastack`). Esto nos permitir√°:

- Tener mensajes de error m√°s claros.
- Identificar r√°pidamente la causa ra√≠z del problema.
- Integrar estas excepciones de manera fluida dentro de un flujo reactivo con `Mono.error()`.

### Excepciones Personalizadas

Cuando no se encuentra una noticia para una fecha dada:

````java
public class ExternalNewsNotFoundException extends RuntimeException {
    public ExternalNewsNotFoundException(String date) {
        super(Constants.DATA_NOT_FOUND_MESSAGE.formatted(date));
    }
}
````

Cuando la petici√≥n al servicio externo es inv√°lida (ejemplo: par√°metros incorrectos):

````java
public class ExternalInvalidNewsRequestException extends RuntimeException {
    public ExternalInvalidNewsRequestException(String message) {
        super(message);
    }
}
````

Cuando ocurre un error gen√©rico en el servicio externo (timeouts, 5xx, etc.):

````java
public class ExternalServiceException extends RuntimeException {
    public ExternalServiceException(String message) {
        super(message);
    }
}
````

### Clase de Utilidad para Errores Reactivos

En aplicaciones reactivas (`WebFlux`) es com√∫n propagar errores dentro de un flujo (`Mono` o `Flux`).
Para evitar repetir `Mono.error(new MiExcepcion(...))` en todo el c√≥digo, centralizamos esa l√≥gica en una clase de
utilidad:

````java

@NoArgsConstructor(access = AccessLevel.PRIVATE)
public class ApplicationExceptions {
    public static <T> Mono<T> externalNewsNotFound(String date) {
        return Mono.error(() -> new ExternalNewsNotFoundException(date));
    }

    public static <T> Mono<T> externalInvalidNewsRequest(String message) {
        return Mono.error(() -> new ExternalInvalidNewsRequestException(message));
    }

    public static <T> Mono<T> externalServiceError(String message) {
        return Mono.error(() -> new ExternalServiceException(message));
    }
}
````

## Definiendo componente del servicio externo

En este apartado creamos el componente `MediaStackServiceClient`, que ser√° el encargado de comunicarse con el servicio
externo de noticias `MediaStack API`.

La URL base de `MediaStack` que consumiremos es:

````bash
https://api.mediastack.com/v1/news?access_key=922887e602f7b3a4cdebdd6b3fd7a2c6&limit=5&countries=pe&date=2025-09-22
````

### Implementaci√≥n del Cliente

````java

@Slf4j
@Component
public class MediaStackServiceClient {

    private static final String ACCESS_KEY = "922887e602f7b3a4cdebdd6b3fd7a2c6";
    private static final String COUNTRIES = "pe";
    private static final int LIMIT = 5;

    private final WebClient client;

    public MediaStackServiceClient(WebClient.Builder builder) {
        this.client = builder.build();
    }

    public Mono<NewsResponse> getNews(String date) {
        log.info("Consultando noticias en MediaStack para la fecha: {}", date);
        return this.client.get()
                .uri("/v1/news", uriBuilder -> uriBuilder
                        .queryParam("access_key", ACCESS_KEY)
                        .queryParam("limit", LIMIT)
                        .queryParam("countries", COUNTRIES)
                        .queryParam("date", date)
                        .build())
                .retrieve()
                .bodyToMono(NewsResponse.class)
                .onErrorResume(WebClientResponseException.NotFound.class, exception -> {
                    log.warn("No se encontraron noticias en MediaStack para la fecha: {}. C√≥digo HTTP: {}, mensaje: {}",
                            date, exception.getStatusCode(), exception.getMessage());
                    return ApplicationExceptions.externalNewsNotFound(date);
                })
                .onErrorResume(WebClientResponseException.BadRequest.class, exception -> {
                    log.error("Solicitud inv√°lida al API de MediaStack. Fecha: {}, c√≥digo HTTP: {}, mensaje: {}",
                            date, exception.getStatusCode(), exception.getMessage());
                    return ApplicationExceptions.externalInvalidNewsRequest(exception.getMessage());
                })
                .onErrorResume(throwable -> {
                    log.error("Error inesperado consultando MediaStack. Fecha: {}, tipo: {}, mensaje: {}",
                            date, throwable.getClass().getSimpleName(), throwable.getMessage());
                    return ApplicationExceptions.externalServiceError(throwable.getMessage());
                });
    }
}
````

1. Uso de `WebClient`
    - Inyectamos `WebClient.Builder` desde el contexto de Spring y lo construimos en el constructor.
    - Esto garantiza que respete la configuraci√≥n centralizada (`baseUrl` definida en `WebClientConfig`).

2. Par√°metros de consulta (`queryParam`)
    - `access_key`: clave de autenticaci√≥n de MediaStack.
    - `limit`: l√≠mite de noticias a traer (en este caso 5).
    - `countries`: pa√≠s filtrado (ejemplo pe).
    - `date`: fecha solicitada.

3. Manejo de errores
    - `404 Not Found` ‚Üí `ExternalNewsNotFoundException`
    - `400 Bad Request` ‚Üí `ExternalInvalidNewsRequestException`
    - Cualquier otro error ‚Üí `ExternalServiceException`
    - Cada uno se propaga como `Mono.error(...)` mediante la clase utilitaria `ApplicationExceptions`.

4. Logging enriquecido
    - Se registran logs en distintos niveles (`info`, `warn`, `error`) seg√∫n el tipo de respuesta, lo que facilita el
      troubleshooting.

### Resumen

- Este componente encapsula la comunicaci√≥n con MediaStack.
- Usa WebClient (no bloqueante) y retorna un `Mono<NewsResponse>` acorde al stack reactivo.
- Incluye manejo de errores robusto con excepciones personalizadas.
- Es el punto central de integraci√≥n con el servicio externo y ser√° usado m√°s adelante por la l√≥gica de negocio del
  `worker-service`.

# [Comunicaci√≥n as√≠ncrona entre microservicios usando SpringBoot 3 con Kafka, Redis y Docker](https://www.youtube.com/watch?v=kIc3ORaZM-I)

---

## Arquitectura del proyecto

La soluci√≥n se compone de dos microservicios que se comunican de manera as√≠ncrona mediante `Kafka`, y que utilizan un
`Redis` compartido como `sistema de cach√©`.

### 1. News Service

- Expone una `API REST` para que los clientes consulten noticias.
- Flujo:
    - Revisa primero si la noticia solicitada se encuentra en `Redis`.
    - Si existe en cach√© ‚Üí responde inmediatamente al cliente.
    - Si no existe en cach√© ‚Üí produce un mensaje en `Kafka (news-topic)` indicando que debe obtenerse esa noticia.

### 2. Worker Service

- Est√° suscrito al topic `news-topic`.
- Flujo:
    - Escucha el mensaje enviado por el `news-service`.
    - Verifica en `Redis` si ya existe la noticia.
    - Si no est√° ‚Üí consulta la API externa `Mediastack`.
    - Guarda la respuesta obtenida en `Redis`, quedando disponible para futuras consultas.

#### 3. Redis (√∫nico y compartido)

- Ambos servicios se conectan a la misma instancia de `Redis`, que act√∫a como cach√© centralizada.
- Permite que:
    - El `news-service` pueda responder r√°pidamente si la noticia ya fue procesada.
    - El `worker-service` guarde los resultados para que luego el `news-service` los entregue a los clientes.

![01.png](assets/01.png)

### Nota sobre la integraci√≥n con Redis

En este proyecto, ambos microservicios se conectan a la misma instancia de `Redis`, pero cada uno utiliza un cliente
diferente para prop√≥sitos de pr√°ctica y aprendizaje:

- `News Service`. Se conecta a `Redis` utilizando la dependencia `spring-boot-starter-data-redis-reactive`, la cual
  internamente emplea el cliente `Lettuce`. Esta elecci√≥n est√° alineada con el contenido del curso principal, ya que se
  centra en trabajar con `Spring Data Redis` en su variante reactiva.


- `Worker Service`. En este caso `no se usa` `Spring Data Redis Reactive`. En su lugar, se integra `Redis` a trav√©s de
  `redisson-spring-boot-starter`, aprovechando el cliente `Redisson`. Esta decisi√≥n se tom√≥ como parte de la pr√°ctica
  de un curso previo de `Redis`, lo que permite explorar un enfoque alternativo de conexi√≥n y manejo de datos en
  `Redis`.

De esta forma, aunque ambos microservicios comparten la misma instancia de `Redis` como sistema de cach√© centralizado,
cada uno lo hace con un cliente distinto, lo que enriquece el aprendizaje y la comparaci√≥n entre enfoques.

## Creando proyecto: [news-service](https://start.spring.io/#!type=maven-project&language=java&platformVersion=3.5.5&packaging=jar&jvmVersion=21&groupId=dev.magadiflo&artifactId=news-service&name=news-service&description=Demo%20project%20for%20Spring%20Boot&packageName=dev.magadiflo.news.app&dependencies=webflux,lombok,data-redis-reactive,kafka,validation)

Creamos el proyecto `news-service` desde spring initializr con las siguientes dependencias.

````xml
<!--Spring Boot 3.5.5-->
<!--Java 21-->
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-redis-reactive</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-validation</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-webflux</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>

    <dependency>
        <groupId>org.projectlombok</groupId>
        <artifactId>lombok</artifactId>
        <optional>true</optional>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-test</artifactId>
        <scope>test</scope>
    </dependency>
    <dependency>
        <groupId>io.projectreactor</groupId>
        <artifactId>reactor-test</artifactId>
        <scope>test</scope>
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka-test</artifactId>
        <scope>test</scope>
    </dependency>
</dependencies>
````

> `Nota`: usamos `spring-boot-starter-data-redis-reactive` porque `WebFlux` est√° basado en el paradigma reactivo. Esto
> garantiza operaciones no bloqueantes tambi√©n en el acceso a `Redis`.

## Configuraci√≥n de News Service

Definimos las configuraciones b√°sicas para que nuestro `news-service` pueda conectarse a `Kafka` y a `Redis`.

````yml
server:
  port: 8080
  error:
    include-message: always

spring:
  application:
    name: news-service
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS}
  data:
    redis:
      host: ${REDIS_HOST}
      port: ${REDIS_PORT}
      password: ${REDIS_PASSWORD}
````

Explicaci√≥n:

- `spring.kafka.bootstrap-servers`: indica la direcci√≥n de los `brokers de Kafka`.
- `spring.data.redis`: define las credenciales de acceso a `Redis`.
- El uso de variables de entorno (`${...}`) permite mayor portabilidad entre entornos (desarrollo, staging, producci√≥n).

## Configuraci√≥n de Producer y Topic en Kafka

Para que el `News Service` pueda publicar mensajes en `Kafka`, es necesario configurar un `Producer` y definir el
`Topic` donde se enviar√°n dichos mensajes.

A continuaci√≥n, se muestran las clases de configuraci√≥n:

### Configuraci√≥n del Producer

En esta clase se define el `ProducerFactory` y el `KafkaTemplate`.

- El `ProducerFactory` se encarga de crear instancias de productores con las propiedades definidas.
- El `KafkaTemplate` es el componente que abstrae y simplifica el env√≠o de mensajes a `Kafka`.

````java

@Configuration
public class KafkaProducerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    // Propiedades del Producer
    public Map<String, Object> producerConfig() {
        Map<String, Object> props = new HashMap<>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, this.bootstrapServers);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return props;
    }

    // Crea el ProducerFactory
    @Bean
    public ProducerFactory<String, String> producerFactory() {
        return new DefaultKafkaProducerFactory<>(this.producerConfig());
    }

    // Define el KafkaTemplate para enviar mensajes
    @Bean
    public KafkaTemplate<String, String> kafkaTemplate(ProducerFactory<String, String> producerFactory) {
        return new KafkaTemplate<>(producerFactory);
    }
}
````

### Definiendo constantes

En esta clase de utilidad creamos las constantes que estaremos usando en nuestra aplicaci√≥n.

````java

@UtilityClass
public class Constants {
    public static final String TOPIC_NAME = "news-topic";
    public static final String DATE_FORMAT = "^\\d{4}-\\d{2}-\\d{2}$";
    public static final String DATE_NOT_BLANK_MESSAGE = "El par√°metro de solicitud de fecha no puede estar vac√≠o o nulo";
    public static final String DATE_PATTERN_MESSAGE = "La fecha debe estar en el formato yyyy-MM-dd";
    public static final String DATA_FOUND_MESSAGE = "Datos encontrados";
    public static final String DATA_NOT_FOUND_MESSAGE = "La noticia solicitada para la fecha [%s] a√∫n no est√° disponible. Por favor, intente nuevamente en unos momentos";
}
````

### Configuraci√≥n del Topic

En esta clase se define el topic `news-topic`, el cual ser√° creado autom√°ticamente al iniciar la aplicaci√≥n si no
existe en el cluster de `Kafka`.

````java

@Configuration
public class KafkaTopicConfig {
    @Bean
    public NewTopic generateTopic() {
        return TopicBuilder.name(Constants.TOPIC_NAME).build();
    }
}
````

> üìå `Nota`: Esta configuraci√≥n es suficiente para entornos de desarrollo o pruebas. En entornos productivos, es
> recomendable especificar expl√≠citamente el `n√∫mero de particiones` y `r√©plicas` para garantizar escalabilidad y
> tolerancia a fallos.

## Configuraci√≥n de Redis en news-service

En el `News Service`, se utiliza `Spring Data Redis Reactive` junto con el cliente `Lettuce` para interactuar con
`Redis` de manera reactiva.

Esto permite realizar operaciones no bloqueantes, algo muy √∫til en aplicaciones basadas en `Spring WebFlux`.

````java

@Configuration
public class RedisConfig {
    @Value("${spring.data.redis.host}")
    private String redisHost;

    @Value("${spring.data.redis.port}")
    private Integer redisPort;

    @Value("${spring.data.redis.password}")
    private String redisPassword;

    // Configuraci√≥n de conexi√≥n
    @Bean
    public ReactiveRedisConnectionFactory reactiveRedisConnectionFactory() {
        var redisStandaloneConfiguration = new RedisStandaloneConfiguration();
        redisStandaloneConfiguration.setHostName(Objects.requireNonNull(this.redisHost));
        redisStandaloneConfiguration.setPort(Objects.requireNonNull(this.redisPort));
        redisStandaloneConfiguration.setPassword(Objects.requireNonNull(this.redisPassword));
        return new LettuceConnectionFactory(redisStandaloneConfiguration);
    }

    // Configuraci√≥n del template reactivo con serializadores
    @Bean
    public ReactiveRedisOperations<String, Object> reactiveRedisOperations(ReactiveRedisConnectionFactory reactiveRedisConnectionFactory) {
        Jackson2JsonRedisSerializer<Object> serializer = new Jackson2JsonRedisSerializer<>(Object.class); // Para serializar el value
        RedisSerializationContext.RedisSerializationContextBuilder<String, Object> builder =
                RedisSerializationContext.newSerializationContext(new StringRedisSerializer()); // Para serializar la key
        RedisSerializationContext<String, Object> context = builder
                .value(serializer)
                .hashKey(serializer)
                .hashValue(serializer)
                .build();
        return new ReactiveRedisTemplate<>(reactiveRedisConnectionFactory, context);
    }
}
````

Explicaci√≥n paso a paso

1. `Propiedades externas`
    - `spring.data.redis.host` ‚Üí Direcci√≥n del servidor Redis.
    - `spring.data.redis.port` ‚Üí Puerto de Redis.
    - `spring.data.redis.password` ‚Üí Contrase√±a (si est√° configurada en Redis).

   Estas propiedades se inyectan desde el `application.yml`.

2. `ReactiveRedisConnectionFactory`
    - Se crea una instancia de `RedisStandaloneConfiguration` para indicar `host`, `puerto` y `password`.
    - Se usa `LettuceConnectionFactory`, que es el driver por defecto recomendado para `Redis` en entornos reactivos.
    - Este `ConnectionFactory` ser√° la encargada de abrir conexiones reactivas hacia Redis.

3. `ReactiveRedisOperations`
    - Se construye un `ReactiveRedisTemplate`, que es el componente principal para interactuar con Redis de forma
      reactiva.
    - Para serializar las `keys`, se usa `StringRedisSerializer`.
    - Para serializar los `values` y objetos m√°s complejos, se usa `Jackson2JsonRedisSerializer<Object>`.
    - Tambi√©n se configuran las serializaciones de `hashKey` y `hashValue` para soportar estructuras de tipo `Hash`
      en `Redis`.

En pocas palabras:

- `Keys` ‚Üí guardadas como String.
- `Values` ‚Üí guardados en formato JSON (gracias a `Jackson`).

## Creaci√≥n del DAO para acceder a Redis

Para mantener una separaci√≥n clara entre la l√≥gica de negocio y el acceso a datos, se implementa un
`DAO (Data Access Object)` que encapsula las operaciones contra `Redis`. De esta forma, la aplicaci√≥n puede
interactuar con la cach√© sin acoplarse directamente a la `API` de `ReactiveRedisOperations`.

### Interfaz NewsDao

La interfaz define las operaciones disponibles para acceder a las noticias en `Redis`. En este caso, √∫nicamente se
consulta si existe una noticia asociada a una fecha espec√≠fica.

````java
public interface NewsDao {
    Mono<Object> getNews(String date);
}
````

- `Mono<Object>` ‚Üí dado que estamos en un contexto reactivo, el m√©todo devuelve un `Mono`, que representa un valor
  as√≠ncrono (puede contener la noticia o estar vac√≠o si no existe en `Redis`).
- `String date` ‚Üí se usa la fecha como clave en `Redis`. En un caso real, podr√≠a considerarse un identificador m√°s
  rico (ej. `news:2025-09-16`) para evitar colisiones.

### Implementaci√≥n NewsDaoImpl

La implementaci√≥n utiliza el `ReactiveRedisOperations` configurado previamente para interactuar con `Redis`.

````java

@RequiredArgsConstructor
@Repository
public class NewsDaoImpl implements NewsDao {

    private final ReactiveRedisOperations<String, Object> reactiveRedisOperations;

    @Override
    public Mono<Object> getNews(String date) {
        return this.reactiveRedisOperations.opsForValue().get(date);
    }
}
````

- `@Repository` ‚Üí marca la clase como componente de acceso a datos.
- `@RequiredArgsConstructor (Lombok)` ‚Üí genera autom√°ticamente un constructor con los argumentos final, en este caso
  `reactiveRedisOperations`.
- `opsForValue().get(date)` ‚Üí obtiene el valor almacenado en `Redis` para la clave proporcionada (la fecha).

## Servicio de Noticias (`NewsService`)

El servicio se encarga de:

1. Consultar `Redis` para ver si la noticia solicitada ya est√° disponible.
2. Si la encuentra `(cache HIT)` ‚Üí devolverla al cliente.
3. Si no existe `(cache MISS)` ‚Üí publicar un mensaje en `Kafka` para que el `worker-service` procese la solicitud y
   obtenga la noticia desde la API externa.

### Interfaz

````java
public interface NewsService {
    Mono<Object> getNews(String date);

    Mono<Void> publishToMessageBroker(String date);
}
````

- `getNews(String date)`: consulta si existe la noticia en `Redis`, y si no, dispara el flujo de publicaci√≥n a `Kafka`.
- `publishToMessageBroker(String date)`: env√≠a un mensaje al `topic` de `Kafka` con la fecha solicitada.

> ‚ö†Ô∏è `Nota`: por ahora el retorno es `Mono<Object>`, pero cuando tengamos el DTO definido conviene tipar la respuesta
> `(Mono<NewsDto>)` para trabajar de manera m√°s segura.

### Implementaci√≥n

````java

@Slf4j
@RequiredArgsConstructor
@Service
public class NewsServiceImpl implements NewsService {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final NewsDao newsDao;

    @Override
    public Mono<Object> getNews(String date) {
        return this.newsDao.getNews(date)
                .doOnNext(value -> log.info("Cache HIT - Obteniendo desde Redis para fecha: {}", value))
                .switchIfEmpty(Mono.defer(() -> {
                    log.info("Cache MISS - Publicando fecha {} en Kafka", date);
                    return this.publishToMessageBroker(date);
                }));
    }

    @Override
    public Mono<Void> publishToMessageBroker(String date) {
        Message<String> message = MessageBuilder
                .withPayload(date)
                .setHeader(KafkaHeaders.TOPIC, Constants.TOPIC_NAME)
                .build();
        return Mono.fromFuture(() -> this.kafkaTemplate.send(message))
                .then();
    }
}
````

Explicaci√≥n del flujo

1. `newsDao.getNews(date)` ‚Üí busca la noticia en Redis.
2. Si existe:
    - Se loguea `Cache HIT`.
    - Se devuelve directamente el valor encontrado.
3. Si no existe:
    - Se loguea Cache MISS.
    - Se invoca `publishToMessageBroker(date)`, que construye un mensaje y lo env√≠a a `Kafka`.

## üß≠ Cat√°logo de errores de negocio en APIs (`ErrorCatalog`)

En arquitecturas modernas de backend, especialmente en APIs REST, es com√∫n complementar los c√≥digos HTTP est√°ndar
con un `cat√°logo de errores de negocio`. Este cat√°logo permite identificar con precisi√≥n el origen del error, facilitar
la trazabilidad en observabilidad, y ofrecer mensajes claros y consistentes a los consumidores de la API.

### üéØ Prop√≥sito del cat√°logo

El `enum` `ErrorCatalog` centraliza los errores que pueden ocurrir en la l√≥gica de negocio o en validaciones
espec√≠ficas. Cada entrada del cat√°logo contiene:

- `code`: Identificador √∫nico del error, siguiendo una convenci√≥n definida por el equipo (e.g. `NEWS_MS_001`).
- `message`: Descripci√≥n legible del error, √∫til para mostrar al cliente o registrar en logs.

Esto permite desacoplar los errores t√©cnicos del protocolo HTTP de los errores funcionales del dominio.

### üß± Ejemplo de implementaci√≥n

````java

@Getter
@RequiredArgsConstructor
public enum ErrorCatalog {

    INVALID_PARAMETERS("NEWS_MS_001", "Par√°metro de solicitud de fecha no v√°lido"),
    INTERVAL_SERVER_ERROR("NEWS_MS_002", "Error Interno del Servidor");

    private final String code;
    private final String message;
}
````

### üîç Diferencias entre errores HTTP y errores de negocio

| Aspecto                        | C√≥digo HTTP (`400`, `500`, etc.) | C√≥digo de cat√°logo (`NEWS_MS_001`)             |
|--------------------------------|----------------------------------|------------------------------------------------|
| Prop√≥sito                      | Indicar tipo de error t√©cnico    | Identificar error espec√≠fico de negocio        |
| Granularidad                   | Limitada                         | Detallada y extensible                         |
| Trazabilidad en observabilidad | Dif√≠cil de rastrear sin contexto | F√°cil de rastrear en logs, dashboards, alertas |
| Mensaje para el cliente        | Gen√©rico                         | Personalizados y claros                        |
| Mantenibilidad                 | No versionable                   | Versionable y documentable                     |

### üì¶ Ejemplo de respuesta en API

Esta estructura puede acompa√±ar un c√≥digo `HTTP 400 Bad Request`, pero el code interno permite identificar el error
exacto en dashboards, logs o alertas.

````json
{
  "code": "NEWS_MS_001",
  "message": "Par√°metro de solicitud de fecha no v√°lido"
}
````

### üõ†Ô∏è Buenas pr√°cticas de dise√±o

- `Convenci√≥n de c√≥digos`: Usa prefijos por m√≥dulo (NEWS_MS, USER_MS, etc.) y numeraci√≥n secuencial.
- `Centralizaci√≥n`: Mant√©n el cat√°logo en un √∫nico enum o agr√∫palo por dominio si crece demasiado.
- `Versionado`: Documenta los cambios en el cat√°logo para evitar rupturas en clientes.
- `Integraci√≥n con observabilidad`: Exp√≥n el code en logs estructurados, trazas y m√©tricas.
- `Mensajes legibles`: Evita mensajes t√©cnicos cr√≠pticos, prioriza claridad para el consumidor.

## DTOs de Respuesta

Para garantizar que la API tenga un contrato consistente tanto en respuestas exitosas como en errores, definimos los
siguientes DTOs:

### 1. Tipos de Error (ErrorType)

- `FUNCTIONAL` ‚Üí Por ejemplo, cuando un par√°metro no es v√°lido o una noticia solicitada no existe.
- `SYSTEM` ‚Üí Por ejemplo, fallas en la comunicaci√≥n con `Kafka`, `Redis`, o errores internos inesperados.

````java
public enum ErrorType {
    FUNCTIONAL, // Errores relacionados con reglas de negocio
    SYSTEM      // Errores relacionados con el sistema o infraestructura
}
````

### 2. Respuesta exitosa (DataResponse)

````java
public record DataResponse<T>(String message,
                              Boolean status,
                              @JsonInclude(JsonInclude.Include.NON_NULL)
                              T data) {
}
````

- `message` ‚Üí mensaje gen√©rico para el cliente (ej: "Operaci√≥n exitosa").
- `status` ‚Üí indica si la operaci√≥n fue correcta (true/false).
- `data` ‚Üí el contenido real de la respuesta (puede ser un DTO, lista, etc.).
- ‚ö†Ô∏è `Si data es null`, no se incluye en el JSON gracias a `@JsonInclude(JsonInclude.Include.NON_NULL)`.

### 3. Respuesta de error (ErrorResponse)

````java
public record ErrorResponse(String code,
                            String message,
                            ErrorType errorType,
                            List<String> details,
                            LocalDateTime timestamp) {
}
````

- `code` ‚Üí c√≥digo de error definido en el cat√°logo (`NEWS_MS_001`, `NEWS_MS_002`, etc.).
- `message` ‚Üí descripci√≥n breve y clara del error.
- `errorType` ‚Üí indica si es un error `FUNCTIONAL` o `SYSTEM`.
- `details` ‚Üí lista de detalles adicionales (ej. campos inv√°lidos).
- `timestamp` ‚Üí momento exacto en que ocurri√≥ el error.

### ‚úÖ Beneficios de este dise√±o

- Estandariza las respuestas, tanto exitosas como de error.
- Facilita el consumo de la API, ya que el cliente sabe siempre qu√© campos esperar.
- Permite extender f√°cilmente la estructura (ej. agregar un campo de requestId en el futuro para trazabilidad).

## Excepciones personalizadas

En la aplicaci√≥n definimos excepciones propias para representar errores de negocio de forma clara y controlada. Esto
permite separar los errores funcionales de los errores t√©cnicos, y facilitar el manejo centralizado de excepciones en
la capa de controladores.

### 1. Excepci√≥n espec√≠fica: `NewsNotFoundException`

````java
public class NewsNotFoundException extends RuntimeException {
    public NewsNotFoundException(String date) {
        super(Constants.DATA_NOT_FOUND_MESSAGE.formatted(date));
    }
}
````

- Extiende de `RuntimeException`, lo que la hace no chequeada `(unchecked)`.
- Se lanza cuando una noticia no existe ni en `Redis` ni en la `API externa`.
- Usa el mensaje predefinido en `Constants.DATA_NOT_FOUND_MESSAGE`, formateado con la fecha solicitada.

### 2. F√°brica de excepciones: `ApplicationExceptions`

````java

@NoArgsConstructor(access = AccessLevel.PRIVATE)
public class ApplicationExceptions {
    public static <T> Mono<T> newsNotFound(String date) {
        return Mono.error(() -> new NewsNotFoundException(date));
    }
}
````

- Clase utilitaria y est√°tica (constructor privado) para centralizar la creaci√≥n de errores en formato reactivo
  `(Mono.error)`.
- `newsNotFound(String date)` retorna un `Mono.error` que emite la excepci√≥n `NewsNotFoundException`.

### ‚úÖ Beneficios de este enfoque

- Separa las excepciones de negocio (`NewsNotFound`) de los errores t√©cnicos.
- Estandariza la forma en que se generan errores reactivos (`ApplicationExceptions`).
- Facilita el futuro manejo global con un `@RestControllerAdvice`, devolviendo un `ErrorResponse` consistente al
  cliente.

## Lanzando excepci√≥n en servicio `NewsServiceImpl`

Cuando una noticia no se encuentra en `Redis`, ocurren dos acciones encadenadas:

1. Se publica un mensaje en el topic de `Kafka`, para que el `worker-service` procese la solicitud.
2. Se lanza una excepci√≥n `NewsNotFoundException`, que posteriormente ser√° capturada por nuestro handler global de
   errores y devuelta al cliente en un formato consistente (`ErrorResponse`).

De esta forma:

- El cliente recibe una respuesta inmediata, sin quedar bloqueado esperando a `Kafka`.
- El `worker-service` se encarga en segundo plano de consultar la API externa y guardar el resultado en `Redis` para
  futuras peticiones.

````java

@Slf4j
@RequiredArgsConstructor
@Service
public class NewsServiceImpl implements NewsService {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final NewsDao newsDao;

    @Override
    public Mono<Object> getNews(String date) {
        return this.newsDao.getNews(date)
                .doOnNext(value -> log.info("Cache HIT - Obteniendo desde Redis para fecha: {}", value))
                .switchIfEmpty(Mono.defer(() -> {
                    log.info("Cache MISS - Publicando fecha {} en Kafka", date);
                    return this.publishToMessageBroker(date) // Cuando termine la publicaci√≥n ‚Üí lanzamos excepci√≥n
                            .then(ApplicationExceptions.newsNotFound(date));
                }));
    }

    @Override
    public Mono<Void> publishToMessageBroker(String date) {
        Message<String> message = MessageBuilder
                .withPayload(date)
                .setHeader(KafkaHeaders.TOPIC, Constants.TOPIC_NAME)
                .build();
        return Mono.fromFuture(() -> this.kafkaTemplate.send(message))
                .then();
    }
}
````

### üîé Puntos clave

- `Mono.defer(...)`: garantiza que la publicaci√≥n en `Kafka` y la excepci√≥n solo se ejecuten si el flujo viene vac√≠o
  (cache miss).
- `.then(ApplicationExceptions.newsNotFound(date))`: asegura que la excepci√≥n se dispare despu√©s de publicar el mensaje.
- Patr√≥n `Cache-Aside + Event-driven`:
    - Si la noticia existe ‚Üí se devuelve directamente desde Redis.
    - Si no existe ‚Üí se dispara el flujo as√≠ncrono y el cliente recibe un mensaje claro de que la solicitud est√° en
      proceso.

## Crea controlador `NewsController`

El controlador expone el endpoint para consultar noticias. Utiliza `NewsService` y retorna un `DataResponse` tipado
para mantener consistencia en las respuestas.

````java

@Slf4j
@RequiredArgsConstructor
@RestController
@RequestMapping(path = "/api/v1/news")
public class NewsController {

    private final NewsService newsService;

    @GetMapping
    public Mono<ResponseEntity<DataResponse<Object>>> getNews(@NotBlank(message = Constants.DATE_NOT_BLANK_MESSAGE)
                                                              @Pattern(regexp = Constants.DATE_FORMAT, message = Constants.DATE_PATTERN_MESSAGE)
                                                              @RequestParam(required = false) String date) {
        return this.newsService.getNews(date)
                .map(data -> ResponseEntity.ok(new DataResponse<>(Constants.DATA_FOUND_MESSAGE, Boolean.TRUE, data)));
    }
}
````

üîé Puntos clave

- `Validaci√≥n de par√°metros`
    - Aunque el par√°metro `date` es obligatorio desde el punto de vista funcional, se define con `required = false`.
    - Esto permite que `Bean Validation` (`@NotBlank`, `@Pattern`) maneje la validaci√≥n en lugar de que `Spring WebFlux`
      lo rechace autom√°ticamente.
        - Si us√°ramos `required = true` (valor por defecto), cuando no enviemos el par√°metro date en el request,
          `Spring` lanzar√≠a una excepci√≥n antes de que nuestras validaciones con `Bean Validation` pudieran aplicarse.
        - De esta forma tenemos control total sobre los mensajes de error y aseguramos que todas las respuestas se
          devuelvan en un formato consistente (`ErrorResponse`).


- `Respuesta uniforme`. El uso de `DataResponse<T>` estandariza la salida.
    - Si existe la noticia en Redis ‚Üí se devuelve con `status = true` y data poblado.
    - Si no existe ‚Üí se lanza `NewsNotFoundException`, que m√°s adelante manejaremos en un handler global de excepciones
      para devolver un `ErrorResponse`.
